conditions:
  # BM25 Monolingual
  - name: bm25-mono.ha
    eval_key: ciral-v1.0-ha
    command: python -m pyserini.search.lucene --language ha --topics ciral-v1.0-ha-${split}-native --index ciral-v1.0-ha --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.2039
            MRR@10: 0.3153
            R@100: 0.2760
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100: 
  - name: bm25-mono.so
    eval_key: ciral-v1.0-so
    command: python -m pyserini.search.lucene --language so --topics ciral-v1.0-so-${split}-native --index ciral-v1.0-so --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.1500
            MRR@10: 0.4000
            R@100: 0.1850
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: bm25-mono.sw
    eval_key: ciral-v1.0-sw
    command: python -m pyserini.search.lucene --language sw --topics ciral-v1.0-sw-${split}-native --index ciral-v1.0-sw --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.1812
            MRR@10: 0.1681
            R@100: 0.4742
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: bm25-mono.yo
    eval_key: ciral-v1.0-yo
    command: python -m pyserini.search.lucene --language yo --topics ciral-v1.0-yo-${split}-native --index ciral-v1.0-yo --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.2797
            MRR@10: 0.3833
            R@100: 0.5114
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  

  # BM25 Machine QT
  - name: bm25-qt.ha
    eval_key: ciral-v1.0-ha
    command: python -m pyserini.search.lucene --language ha --topics ciral-v1.0-ha-${split}-qt --index ciral-v1.0-ha --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.1168
            MRR@10: 0.1825
            R@100: 0.2933 
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100: 
  - name: bm25-qt.so
    eval_key: ciral-v1.0-so
    command: python -m pyserini.search.lucene --language so --topics ciral-v1.0-so-${split}-qt --index ciral-v1.0-so --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.0420
            MRR@10: 0.1000
            R@100: 0.0500
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: bm25-qt.sw
    eval_key: ciral-v1.0-sw
    command: python -m pyserini.search.lucene --language sw --topics ciral-v1.0-sw-${split}-qt --index ciral-v1.0-sw --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.1690
            MRR@10: 0.1556
            R@100: 0.4665
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: bm25-qt.yo
    eval_key: ciral-v1.0-yo
    command: python -m pyserini.search.lucene --language yo --topics ciral-v1.0-yo-${split}-qt --index ciral-v1.0-yo --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.3315
            MRR@10: 0.3625
            R@100: 0.4808 
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
          

  # BM25 Machine DT
  - name: bm25-dt.ha
    eval_key: ciral-v1.0-ha
    command: python -m pyserini.search.lucene --language ha --topics ciral-v1.0-ha-${split} --index ciral-v1.0-ha-en --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.1454
            MRR@10: 0.1187
            R@100: 0.3892 
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100: 
  - name: bm25-dt.so
    eval_key: ciral-v1.0-so
    command: python -m pyserini.search.lucene --language so --topics ciral-v1.0-so-${split} --index ciral-v1.0-so-en --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.1616
            MRR@10: 0.2533
            R@100: 0.4728
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: bm25-dt.sw
    eval_key: ciral-v1.0-sw
    command: python -m pyserini.search.lucene --language sw --topics ciral-v1.0-sw-${split} --index ciral-v1.0-sw-en --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.2571
            MRR@10: 0.3118
            R@100: 0.5612
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: bm25-dt.yo
    eval_key: ciral-v1.0-yo
    command: python -m pyserini.search.lucene --language yo --topics ciral-v1.0-yo-${split} --index ciral-v1.0-yo-en --output $output --batch 128 --threads 16 --bm25 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.3473
            MRR@10: 0.4158
            R@100: 0.5901
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:

  # mdpr-tied-pft-msmarco
  - name: mdpr-tied-pft-msmarco.ha
    eval_key: ciral-v1.0-ha
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/mdpr-tied-pft-msmarco --topics ciral-v1.0-ha-${split} --index ciral-v1.0-ha-mdpr-tied-pft-msmarco --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.0052
            MRR@10: 0.000
            R@100: 0.1567
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: mdpr-tied-pft-msmarco.so
    eval_key: ciral-v1.0-so
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/mdpr-tied-pft-msmarco --topics ciral-v1.0-so-${split} --index ciral-v1.0-so-mdpr-tied-pft-msmarco --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.000
            MRR@10: 0.000
            R@100: 0.0767
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: mdpr-tied-pft-msmarco.sw
    eval_key: ciral-v1.0-sw
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/mdpr-tied-pft-msmarco --topics ciral-v1.0-sw-${split} --index ciral-v1.0-sw-mdpr-tied-pft-msmarco --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.0785
            MRR@10: 0.2100
            R@100: 0.3030
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: mdpr-tied-pft-msmarco.yo
    eval_key: ciral-v1.0-yo
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/mdpr-tied-pft-msmarco --topics ciral-v1.0-yo-${split} --index ciral-v1.0-yo-mdpr-tied-pft-msmarco --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.1185
            MRR@10: 0.1452
            R@100: 0.2289
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:

  # mdpr-tied-pft-msmarco-ft-mrtydi
  - name: mdpr-tied-pft-msmarco-ft-all.ha
    eval_key: ciral-v1.0-ha
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/mdpr-tied-pft-msmarco-ft-all --topics ciral-v1.0-ha-${split} --index ciral-v1.0-ha-mdpr-tied-pft-msmarco-ft-all --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.0085
            MRR@10: 0.0250
            R@100: 0.1183
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: mdpr-tied-pft-msmarco-ft-all.so
    eval_key: ciral-v1.0-so
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/mdpr-tied-pft-msmarco-ft-all --topics ciral-v1.0-so-${split} --index ciral-v1.0-so-mdpr-tied-pft-msmarco-ft-all --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.0379
            MRR@10: 0.0333
            R@100: 0.1522
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: mdpr-tied-pft-msmarco-ft-all.sw
    eval_key: ciral-v1.0-sw
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/mdpr-tied-pft-msmarco-ft-all --topics ciral-v1.0-sw-${split} --index ciral-v1.0-sw-mdpr-tied-pft-msmarco-ft-all --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.1341
            MRR@10: 0.2958
            R@100: 0.3391
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: mdpr-tied-pft-msmarco-ft-all.yo
    eval_key: ciral-v1.0-yo
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/mdpr-tied-pft-msmarco-ft-all --topics ciral-v1.0-yo-${split} --index ciral-v1.0-yo-mdpr-tied-pft-msmarco-ft-all --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.0510
            MRR@10: 0.0750
            R@100: 0.2285
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:

  # afriberta-pft-msmarco-ft-mrtydi-latin
  - name: afriberta-pft-msmarco-ft-mrtydi.ha
    eval_key: ciral-v1.0-ha
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/afriberta-dpr-ptf-msmarco-ft-latin-mrtydi --topics ciral-v1.0-ha-${split} --index ciral-v1.0-ha-afriberta-dpr-ptf-msmarco-ft-mrtydi --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.2950
            MRR@10: 0.3833
            R@100: 0.6035
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: afriberta-pft-msmarco-ft-mrtydi.so
    eval_key: ciral-v1.0-so
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/afriberta-dpr-ptf-msmarco-ft-latin-mrtydi --topics ciral-v1.0-so-${split} --index ciral-v1.0-so-afriberta-dpr-ptf-msmarco-ft-mrtydi --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.1509
            MRR@10: 0.2095
            R@100: 0.3044
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: afriberta-pft-msmarco-ft-mrtydi.sw
    eval_key: ciral-v1.0-sw
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/afriberta-dpr-ptf-msmarco-ft-latin-mrtydi --topics ciral-v1.0-sw-${split} --index ciral-v1.0-sw-afriberta-dpr-ptf-msmarco-ft-mrtydi --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.3130
            MRR@10: 0.4775
            R@100: 0.5463
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100:
  - name: afriberta-pft-msmarco-ft-mrtydi.yo
    eval_key: ciral-v1.0-yo
    command: python -m pyserini.search.faiss --encoder-class auto --encoder castorini/afriberta-dpr-ptf-msmarco-ft-latin-mrtydi --topics ciral-v1.0-yo-${split} --index ciral-v1.0-yo-afriberta-dpr-ptf-msmarco-ft-mrtydi --output $output --batch 128 --threads 16 --hits 1000
    splits:
      - split: dev
        scores:
          - nDCG@20: 0.0638
            MRR@10: 0.1200
            R@100: 0.1652
      - split: test
        scores:
          - nDCG@20: 
            MRR@10: 
            R@100: