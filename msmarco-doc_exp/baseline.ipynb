{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20873998it [00:48, 366843.94it/s]"
     ]
    }
   ],
   "source": [
    "# read T5 scores for each seg\n",
    "import collections\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "scores = collections.defaultdict(dict)\n",
    "# Merge all passage scores into a list of scores\n",
    "with open('./d2qseg.dev.tsv') as f_query_run_ids, open(\n",
    "        './mono_preds_d2qseg.dev.t5') as f_pred:\n",
    "    for line_query_passage_id, line_pred in tqdm(zip(f_query_run_ids, f_pred)):\n",
    "        query_id, passage_id, _ = line_query_passage_id.strip().split('\\t')\n",
    "        docseg_id = passage_id.split('.')[0]\n",
    "        _, score = line_pred.strip().split('\\t')\n",
    "        score = float(score)\n",
    "        scores[query_id][docseg_id] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5191985it [00:13, 394191.20it/s]\n",
      "100%|██████████| 5193/5193 [00:05<00:00, 865.89it/s]\n"
     ]
    }
   ],
   "source": [
    "#get T5 for each seg for bm25+d2q top1000 and take maxP for each doc and reranked \n",
    "examples = collections.defaultdict(dict)\n",
    "with open('./run.doc.dev.1000.small.tsv') as fcan, open('./run.monoT5.doc.1000.trec', 'w') as fout:\n",
    "    for line_query_passage_id in tqdm(fcan):\n",
    "        query_id, passage_id, _ = line_query_passage_id.strip().split('\\t')\n",
    "        docseg_id = passage_id.split('.')[0]\n",
    "        doc_id = docseg_id.split('#')[0]\n",
    "        score = scores[query_id][docseg_id]\n",
    "        score = float(score)\n",
    "        if doc_id not in examples[query_id]:\n",
    "            examples[query_id][doc_id] = [score]\n",
    "        else:\n",
    "            examples[query_id][doc_id].append(score)\n",
    "    \n",
    "    for query_id, doc_ids_scores in tqdm(examples.items()):\n",
    "        doc_ids_scores = [\n",
    "            (doc_id, max(scores))\n",
    "            for doc_id, scores in doc_ids_scores.items()]\n",
    "\n",
    "        doc_ids_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        rank = 1\n",
    "        for doc_id, score in doc_ids_scores:\n",
    "            score = math.exp(score)\n",
    "            # Adds small score based on rank to avoid duplicated scores.\n",
    "            score += 1e-6 / rank\n",
    "            fout.write(f'{query_id} Q0 {doc_id} {rank} {score} T5\\n')\n",
    "            rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5193/5193 [00:02<00:00, 2455.47it/s]\n"
     ]
    }
   ],
   "source": [
    "#only takes top 100 for each doc for msmarco_doc_eval.py\n",
    "with open ('./run.monoT5.doc.1000.tsv', 'w') as fout:\n",
    "    for query_id, doc_ids_scores in tqdm(examples.items()):\n",
    "            doc_ids_scores = [\n",
    "                (doc_id, max(scores))\n",
    "                for doc_id, scores in doc_ids_scores.items()]\n",
    "\n",
    "            doc_ids_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            rank = 1\n",
    "            for doc_id, score in doc_ids_scores:\n",
    "                if (rank < 100):\n",
    "                    score = math.exp(score)\n",
    "            # Adds small score based on rank to avoid duplicated scores.\n",
    "                    score += 1e-6 / rank\n",
    "                    fout.write(f'{query_id}\\t{doc_id}\\t{rank}\\n')\n",
    "                rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of Documents ranked for each query is as expected. Evaluating\n",
      "#####################\n",
      "MRR @100: 0.40878809930075677\n",
      "QueriesRanked: 5193\n",
      "#####################\n"
     ]
    }
   ],
   "source": [
    "!python3 ../RA/pyserini/tools/scripts/msmarco/msmarco_doc_eval.py \\\n",
    " --judgments ../RA/pyserini/tools/topics-and-qrels/qrels.msmarco-doc.dev.txt --run ./run.monoT5.doc.1000.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ../RA/pyserini/tools/scripts/msmarco/convert_msmarco_to_trec_run.py --input ./run.monoT5.doc.1000.tsv --output ./run.monoT5.doc.1000.trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map                   \tall\t0.4088\r\n",
      "ndcg_cut_10           \tall\t0.4760\r\n"
     ]
    }
   ],
   "source": [
    "!../RA/pyserini/tools/eval/trec_eval.9.0.4/trec_eval -c -mmap -m ndcg_cut.10\\\n",
    " ../RA/pyserini/tools/topics-and-qrels/qrels.msmarco-doc.dev.txt ./run.monoT5.doc.1000.trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
