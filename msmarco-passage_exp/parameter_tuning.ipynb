{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:35:07.374713Z",
     "start_time": "2020-12-24T05:34:58.212906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4416413, 1)\n",
      "(400782,)\n",
      "rel    11.019489\n",
      "dtype: float64\n",
      "             rel\n",
      "qid pid         \n",
      "3   970816     0\n",
      "    1142680    1\n",
      "    2019206    0\n",
      "    2605131    0\n",
      "    2963098    0\n",
      "    2971685    0\n",
      "    3783924    0\n",
      "    5067083    0\n",
      "    5904778    0\n",
      "    6176208    0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4416413 entries, (3, 970816) to (1185869, 7770561)\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   rel     int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 166.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from collections import defaultdict\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "from pyserini.ltr import *\n",
    "from pyserini.search import get_topics_with_reader\n",
    "\n",
    "def train_data_loader(task='triple', neg_sample=10, cutoff=100, random_seed=12345):\n",
    "    if task == 'triple' or task == 'rank':\n",
    "        fn = f'train_{task}_sampled_with_{neg_sample}_{random_seed}.pickle'\n",
    "    elif task == 'rank_recall' or task == 'rank_hard':\n",
    "        fn = f'train_{task}_sampled_with_{neg_sample}_{cutoff}_{random_seed}.pickle'\n",
    "    else:\n",
    "        raise Exception('unknown parameters')\n",
    "    if os.path.exists(fn):\n",
    "        sampled_train = pd.read_pickle(fn)\n",
    "        print(sampled_train.shape)\n",
    "        print(sampled_train.index.get_level_values('qid').drop_duplicates().shape)\n",
    "        print(sampled_train.groupby('qid').count().mean())\n",
    "        print(sampled_train.head(10))\n",
    "        print(sampled_train.info())\n",
    "        return sampled_train\n",
    "    else:\n",
    "        if task == 'triple':\n",
    "            train = pd.read_csv('collections/msmarco-passage/qidpidtriples.train.full.2.tsv', sep=\"\\t\",\n",
    "                                names=['qid', 'pos_pid', 'neg_pid'], dtype=np.int32)\n",
    "            pos_half = train[['qid', 'pos_pid']].rename(columns={\"pos_pid\": \"pid\"}).drop_duplicates()\n",
    "            pos_half['rel'] = np.int32(1)\n",
    "            neg_half = train[['qid', 'neg_pid']].rename(columns={\"neg_pid\": \"pid\"}).drop_duplicates()\n",
    "            neg_half['rel'] = np.int32(0)\n",
    "            del train\n",
    "            sampled_neg_half = []\n",
    "            for qid, group in tqdm(neg_half.groupby('qid')):\n",
    "                sampled_neg_half.append(group.sample(n=min(neg_sample, len(group)), random_state=random_seed))\n",
    "            sampled_train = pd.concat([pos_half] + sampled_neg_half, axis=0, ignore_index=True)\n",
    "            sampled_train = sampled_train.sort_values(['qid','pid']).set_index(['qid','pid'])\n",
    "            print(sampled_train.shape)\n",
    "            print(sampled_train.index.get_level_values('qid').drop_duplicates().shape)\n",
    "            print(sampled_train.groupby('qid').count().mean())\n",
    "            print(sampled_train.head(10))\n",
    "            print(sampled_train.info())\n",
    "\n",
    "            sampled_train.to_pickle(f'train_{task}_sampled_with_{neg_sample}_{random_seed}.pickle')\n",
    "        elif task == 'rank':\n",
    "            qrel = defaultdict(list)\n",
    "            with open(\"collections/msmarco-passage/qrels.train.tsv\") as f:\n",
    "                for line in f:\n",
    "                    topicid, _, docid, rel = line.strip().split('\\t')\n",
    "                    assert rel == \"1\", line.split(' ')\n",
    "                    qrel[topicid].append(docid)\n",
    "            \n",
    "            qid2pos = defaultdict(list)\n",
    "            qid2neg = defaultdict(list)\n",
    "            with open(\"runs/msmarco-passage/run.train.small.tsv\") as f:\n",
    "                for line in tqdm(f):\n",
    "                    topicid, docid, rank = line.split()\n",
    "                    assert topicid in qrel\n",
    "                    if docid in qrel[topicid]:\n",
    "                        qid2pos[topicid].append(docid)\n",
    "                    else:\n",
    "                        qid2neg[topicid].append(docid)\n",
    "            sampled_train = []\n",
    "            for topicid, pos_list in tqdm(qid2pos.items()):\n",
    "                neg_list = random.sample(qid2neg[topicid], min(len(qid2neg[topicid]), neg_sample))\n",
    "                for positive_docid in pos_list:\n",
    "                    sampled_train.append((int(topicid), int(positive_docid), 1))\n",
    "                for negative_docid in neg_list:\n",
    "                    sampled_train.append((int(topicid), int(negative_docid), 0))\n",
    "            sampled_train = pd.DataFrame(sampled_train,columns=['qid','pid','rel'],dtype=np.int32)\n",
    "            sampled_train = sampled_train.sort_values(['qid','pid']).set_index(['qid','pid'])\n",
    "            print(sampled_train.shape)\n",
    "            print(sampled_train.index.get_level_values('qid').drop_duplicates().shape)\n",
    "            print(sampled_train.groupby('qid').count().mean())\n",
    "            print(sampled_train.head(10))\n",
    "            print(sampled_train.info())\n",
    "\n",
    "            sampled_train.to_pickle(f'train_{task}_sampled_with_{neg_sample}_{random_seed}.pickle')\n",
    "        elif task == 'rank_recall':\n",
    "            qrel = defaultdict(list)\n",
    "            with open(\"../collections/msmarco-passage/qrels.train.tsv\") as f:\n",
    "                for line in f:\n",
    "                    topicid, _, docid, rel = line.strip().split('\\t')\n",
    "                    assert rel == \"1\", line.split(' ')\n",
    "                    qrel[topicid].append(docid)\n",
    "            \n",
    "            qid2pos = defaultdict(list)\n",
    "            qid2neg = defaultdict(list)\n",
    "            with open(\"../runs/msmarco-passage/run.train.small.tsv\") as f:\n",
    "                for line in tqdm(f):\n",
    "                    topicid, docid, rank = line.split()\n",
    "                    assert topicid in qrel\n",
    "                    if docid in qrel[topicid]:\n",
    "                        qid2pos[topicid].append(docid)\n",
    "                    else:\n",
    "                        if int(rank) > cutoff:\n",
    "                            qid2neg[topicid].append(docid)\n",
    "            sampled_train = []\n",
    "            for topicid, pos_list in tqdm(qid2pos.items()):\n",
    "                neg_list = random.sample(qid2neg[topicid], min(len(qid2neg[topicid]), neg_sample))\n",
    "                for positive_docid in pos_list:\n",
    "                    sampled_train.append((int(topicid), int(positive_docid), 1))\n",
    "                for negative_docid in neg_list:\n",
    "                    sampled_train.append((int(topicid), int(negative_docid), 0))\n",
    "            sampled_train = pd.DataFrame(sampled_train,columns=['qid','pid','rel'],dtype=np.int32)\n",
    "            sampled_train = sampled_train.sort_values(['qid','pid']).set_index(['qid','pid'])\n",
    "            print(sampled_train.shape)\n",
    "            print(sampled_train.index.get_level_values('qid').drop_duplicates().shape)\n",
    "            print(sampled_train.groupby('qid').count().mean())\n",
    "            print(sampled_train.head(10))\n",
    "            print(sampled_train.info())\n",
    "\n",
    "            sampled_train.to_pickle(f'train_{task}_sampled_with_{neg_sample}_{cutoff}_{random_seed}.pickle')\n",
    "        elif task == 'rank_hard':\n",
    "            qrel = defaultdict(list)\n",
    "            with open(\"../collections/msmarco-passage/qrels.train.tsv\") as f:\n",
    "                for line in f:\n",
    "                    topicid, _, docid, rel = line.strip().split('\\t')\n",
    "                    assert rel == \"1\", line.split(' ')\n",
    "                    qrel[topicid].append(docid)\n",
    "            \n",
    "            qid2pos = defaultdict(list)\n",
    "            qid2neg = defaultdict(list)\n",
    "            with open(\"../runs/msmarco-passage/run.train.small.tsv\") as f:\n",
    "                for line in tqdm(f):\n",
    "                    topicid, docid, rank = line.split()\n",
    "                    assert topicid in qrel\n",
    "                    if docid in qrel[topicid]:\n",
    "                        qid2pos[topicid].append(docid)\n",
    "                    else:\n",
    "                        if int(rank) < cutoff:\n",
    "                            qid2neg[topicid].append(docid)\n",
    "            sampled_train = []\n",
    "            for topicid, pos_list in tqdm(qid2pos.items()):\n",
    "                neg_list = random.sample(qid2neg[topicid], min(len(qid2neg[topicid]), neg_sample))\n",
    "                for positive_docid in pos_list:\n",
    "                    sampled_train.append((int(topicid), int(positive_docid), 1))\n",
    "                for negative_docid in neg_list:\n",
    "                    sampled_train.append((int(topicid), int(negative_docid), 0))\n",
    "            sampled_train = pd.DataFrame(sampled_train,columns=['qid','pid','rel'],dtype=np.int32)\n",
    "            sampled_train = sampled_train.sort_values(['qid','pid']).set_index(['qid','pid'])\n",
    "            print(sampled_train.shape)\n",
    "            print(sampled_train.index.get_level_values('qid').drop_duplicates().shape)\n",
    "            print(sampled_train.groupby('qid').count().mean())\n",
    "            print(sampled_train.head(10))\n",
    "            print(sampled_train.info())\n",
    "\n",
    "            sampled_train.to_pickle(f'train_{task}_sampled_with_{neg_sample}_{cutoff}_{random_seed}.pickle')\n",
    "        else:\n",
    "            raise Exception('unknown parameters')\n",
    "        return sampled_train\n",
    "sampled_train = train_data_loader(task='triple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:35:08.823553Z",
     "start_time": "2020-12-24T05:35:07.376995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6974598, 2)\n",
      "(6980,)\n",
      "rank    999.226074\n",
      "rel     999.226074\n",
      "dtype: float64\n",
      "            rank  rel\n",
      "qid pid              \n",
      "2   55860    345    0\n",
      "    72202    557    0\n",
      "    72210    213    0\n",
      "    98589    278    0\n",
      "    98590    323    0\n",
      "    98593    580    0\n",
      "    98595    553    0\n",
      "    112123   108    0\n",
      "    112126   469    0\n",
      "    112127    21    0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 6974598 entries, (2, 55860) to (1102400, 8830447)\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   rank    int32\n",
      " 1   rel     int32\n",
      "dtypes: int32(2)\n",
      "memory usage: 282.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def dev_data_loader(task='pygaggle'):\n",
    "    if os.path.exists(f'dev_{task}.pickle'):\n",
    "        dev = pd.read_pickle(f'dev_{task}.pickle')\n",
    "        print(dev.shape)\n",
    "        print(dev.index.get_level_values('qid').drop_duplicates().shape)\n",
    "        print(dev.groupby('qid').count().mean())\n",
    "        print(dev.head(10))\n",
    "        print(dev.info())\n",
    "        dev_qrel = pd.read_pickle(f'dev_qrel.pickle')\n",
    "        return dev, dev_qrel\n",
    "    else:\n",
    "        if task == 'rerank':\n",
    "            dev = pd.read_csv('collections/msmarco-passage/top1000.dev', sep=\"\\t\",\n",
    "                              names=['qid', 'pid', 'query', 'doc'], usecols=['qid', 'pid'], dtype=np.int32)\n",
    "        elif task == 'anserini':\n",
    "            dev = pd.read_csv('runs/msmarco-passage/run.msmarco-passage.dev.small.tsv',sep=\"\\t\",\n",
    "                            names=['qid','pid','rank'], dtype=np.int32)\n",
    "        elif task == 'pygaggle':\n",
    "            dev = pd.read_csv('../pygaggle/data/msmarco_ans_entire/run.dev.small.tsv',sep=\"\\t\",\n",
    "                            names=['qid','pid','rank'], dtype=np.int32)\n",
    "        else:\n",
    "            raise Exception('unknown parameters')\n",
    "        dev_qrel = pd.read_csv('collections/msmarco-passage/qrels.dev.small.tsv', sep=\"\\t\",\n",
    "                               names=[\"qid\", \"q0\", \"pid\", \"rel\"], usecols=['qid', 'pid', 'rel'], dtype=np.int32)\n",
    "        dev = dev.merge(dev_qrel, left_on=['qid', 'pid'], right_on=['qid', 'pid'], how='left')\n",
    "        dev['rel'] = dev['rel'].fillna(0).astype(np.int32)\n",
    "        dev = dev.sort_values(['qid','pid']).set_index(['qid','pid'])\n",
    "        \n",
    "        print(dev.shape)\n",
    "        print(dev.index.get_level_values('qid').drop_duplicates().shape)\n",
    "        print(dev.groupby('qid').count().mean())\n",
    "        print(dev.head(10))\n",
    "        print(dev.info())\n",
    "\n",
    "        dev.to_pickle(f'dev_{task}.pickle')\n",
    "        dev_qrel.to_pickle(f'dev_qrel.pickle')\n",
    "        return dev, dev_qrel\n",
    "dev, dev_qrel = dev_data_loader(task='pygaggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:35:18.233519Z",
     "start_time": "2020-12-24T05:35:08.828509Z"
    }
   },
   "outputs": [],
   "source": [
    "def query_loader():\n",
    "    queries = {}\n",
    "    with open('queries.train.small.Flex.json') as f:\n",
    "        for line in f:\n",
    "            query = json.loads(line)\n",
    "            qid = query.pop('id')\n",
    "            query['analyzed'] = query['analyzed'].split(\" \")\n",
    "            query['text'] = query['text'].split(\" \")\n",
    "            query['text_unlemm'] = query['text_unlemm'].split(\" \")\n",
    "            query['text_bert_tok'] = query['text_bert_tok'].split(\" \")\n",
    "            queries[qid] = query\n",
    "    with open('queries.dev.small.Flex.json') as f:\n",
    "        for line in f:\n",
    "            query = json.loads(line)\n",
    "            qid = query.pop('id')\n",
    "            query['analyzed'] = query['analyzed'].split(\" \")\n",
    "            query['text'] = query['text'].split(\" \")\n",
    "            query['text_unlemm'] = query['text_unlemm'].split(\" \")\n",
    "            query['text_bert_tok'] = query['text_bert_tok'].split(\" \")\n",
    "            queries[qid] = query\n",
    "    with open('queries.eval.small.Flex.json') as f:\n",
    "        for line in f:\n",
    "            query = json.loads(line)\n",
    "            qid = query.pop('id')\n",
    "            query['analyzed'] = query['analyzed'].split(\" \")\n",
    "            query['text'] = query['text'].split(\" \")\n",
    "            query['text_unlemm'] = query['text_unlemm'].split(\" \")\n",
    "            query['text_bert_tok'] = query['text_bert_tok'].split(\" \")\n",
    "            queries[qid] = query\n",
    "    return queries\n",
    "queries = query_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:37:36.359941Z",
     "start_time": "2020-12-24T05:35:18.237856Z"
    }
   },
   "outputs": [],
   "source": [
    "fe = FeatureExtractor('../../anserini/indexes/msmarco-passage/lucene-index-msmarco-flex',max(multiprocessing.cpu_count()//2,1))\n",
    "fe.add(BM25(k1=0.82,b=0.68))\n",
    "fe.add(BM25(k1=0.9,b=0.4))\n",
    "fe.add(BM25(k1=1.2,b=0.75))\n",
    "fe.add(BM25(k1=2.0,b=0.75))\n",
    "\n",
    "fe.add(LMDir(mu=1000))\n",
    "fe.add(LMDir(mu=1500))\n",
    "fe.add(LMDir(mu=2500))\n",
    "\n",
    "fe.add(LMJM(0.1))\n",
    "fe.add(LMJM(0.4))\n",
    "fe.add(LMJM(0.7))\n",
    "\n",
    "fe.add(NTFIDF())\n",
    "fe.add(ProbalitySum())\n",
    "\n",
    "fe.add(DFR_GL2())\n",
    "fe.add(DFR_In_expB2())\n",
    "fe.add(DPH())\n",
    "\n",
    "fe.add(Proximity())\n",
    "fe.add(TPscore())\n",
    "fe.add(tpDist())\n",
    "\n",
    "fe.add(DocSize())\n",
    "\n",
    "fe.add(QueryLength())\n",
    "#fe.add(QueryLengthNonStopWords())\n",
    "fe.add(QueryCoverageRatio())\n",
    "fe.add(UniqueTermCount())\n",
    "fe.add(MatchingTermCount())\n",
    "fe.add(SCS())\n",
    "\n",
    "fe.add(tfStat(AvgPooler()))\n",
    "fe.add(tfStat(MedianPooler()))\n",
    "fe.add(tfStat(SumPooler()))\n",
    "fe.add(tfStat(MinPooler()))\n",
    "fe.add(tfStat(MaxPooler()))\n",
    "fe.add(tfStat(VarPooler()))\n",
    "fe.add(tfStat(MaxMinRatioPooler()))\n",
    "fe.add(tfStat(ConfidencePooler()))\n",
    "\n",
    "fe.add(tfIdfStat(AvgPooler()))\n",
    "fe.add(tfIdfStat(MedianPooler()))\n",
    "fe.add(tfIdfStat(SumPooler()))\n",
    "fe.add(tfIdfStat(MinPooler()))\n",
    "fe.add(tfIdfStat(MaxPooler()))\n",
    "fe.add(tfIdfStat(VarPooler()))\n",
    "fe.add(tfIdfStat(MaxMinRatioPooler()))\n",
    "fe.add(tfIdfStat(ConfidencePooler()))\n",
    "\n",
    "fe.add(scqStat(AvgPooler()))\n",
    "fe.add(scqStat(MedianPooler()))\n",
    "fe.add(scqStat(SumPooler()))\n",
    "fe.add(scqStat(MinPooler()))\n",
    "fe.add(scqStat(MaxPooler()))\n",
    "fe.add(scqStat(VarPooler()))\n",
    "fe.add(scqStat(MaxMinRatioPooler()))\n",
    "fe.add(scqStat(ConfidencePooler()))\n",
    "\n",
    "fe.add(normalizedTfStat(AvgPooler()))\n",
    "fe.add(normalizedTfStat(MedianPooler()))\n",
    "fe.add(normalizedTfStat(SumPooler()))\n",
    "fe.add(normalizedTfStat(MinPooler()))\n",
    "fe.add(normalizedTfStat(MaxPooler()))\n",
    "fe.add(normalizedTfStat(VarPooler()))\n",
    "fe.add(normalizedTfStat(MaxMinRatioPooler()))\n",
    "fe.add(normalizedTfStat(ConfidencePooler()))\n",
    "\n",
    "fe.add(idfStat(AvgPooler()))\n",
    "fe.add(idfStat(MedianPooler()))\n",
    "fe.add(idfStat(SumPooler()))\n",
    "fe.add(idfStat(MinPooler()))\n",
    "fe.add(idfStat(MaxPooler()))\n",
    "fe.add(idfStat(VarPooler()))\n",
    "fe.add(idfStat(MaxMinRatioPooler()))\n",
    "fe.add(idfStat(ConfidencePooler()))\n",
    "\n",
    "fe.add(ictfStat(AvgPooler()))\n",
    "fe.add(ictfStat(MedianPooler()))\n",
    "fe.add(ictfStat(SumPooler()))\n",
    "fe.add(ictfStat(MinPooler()))\n",
    "fe.add(ictfStat(MaxPooler()))\n",
    "fe.add(ictfStat(VarPooler()))\n",
    "fe.add(ictfStat(MaxMinRatioPooler()))\n",
    "fe.add(ictfStat(ConfidencePooler()))\n",
    "\n",
    "fe.add(UnorderedSequentialPairs(3))\n",
    "fe.add(UnorderedSequentialPairs(8))\n",
    "fe.add(UnorderedSequentialPairs(15))\n",
    "fe.add(OrderedSequentialPairs(3))\n",
    "fe.add(OrderedSequentialPairs(8))\n",
    "fe.add(OrderedSequentialPairs(15))\n",
    "fe.add(UnorderedQueryPairs(3))\n",
    "fe.add(UnorderedQueryPairs(8))\n",
    "fe.add(UnorderedQueryPairs(15))\n",
    "fe.add(OrderedQueryPairs(3))\n",
    "fe.add(OrderedQueryPairs(8))\n",
    "fe.add(OrderedQueryPairs(15))\n",
    "\n",
    "fe.add(BM25Mean(MaxPooler()))\n",
    "fe.add(BM25Mean(MinPooler()))\n",
    "fe.add(BM25Min(MaxPooler()))\n",
    "fe.add(BM25Min(MinPooler()))\n",
    "fe.add(BM25Max(MaxPooler()))\n",
    "fe.add(BM25Max(MinPooler()))\n",
    "fe.add(BM25HMean(MaxPooler()))\n",
    "fe.add(BM25HMean(MinPooler()))\n",
    "fe.add(BM25Var(MaxPooler()))\n",
    "fe.add(BM25Var(MinPooler()))\n",
    "fe.add(BM25Quartile(MaxPooler()))\n",
    "fe.add(BM25Quartile(MinPooler()))\n",
    "\n",
    "# fe.add(IBMModel1(\"../FlexNeuART/collections/msmarco_doc/derived_data/giza/body\",\"Unlemma\"))\n",
    "# fe.add(IBMModel1(\"../collections/msmarco-passage/text_bert_tok\",\"Bert\",\"BERT\",\"text_bert_tok\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:37:36.373691Z",
     "start_time": "2020-12-24T05:37:36.362263Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract(df, queries, fe):\n",
    "    df_pieces = []\n",
    "    fetch_later = []\n",
    "    qidpid2rel = defaultdict(dict)\n",
    "    need_rows = 0\n",
    "    for qid,group in tqdm(df.groupby('qid')):\n",
    "        for t in group.reset_index().itertuples():\n",
    "            assert t.pid not in qidpid2rel[t.qid]\n",
    "            qidpid2rel[t.qid][t.pid] = t.rel\n",
    "            need_rows += 1\n",
    "        #test.py has bug here, it does not convert pid to str, not sure why it does not cause problem in java\n",
    "        fe.lazy_extract(str(qid),\n",
    "                        [str(pid) for pid in qidpid2rel[t.qid].keys()],\n",
    "                        queries[str(qid)])\n",
    "        fetch_later.append(str(qid))\n",
    "        if len(fetch_later) == 10000:\n",
    "            info = np.zeros(shape=(need_rows,3), dtype=np.int32)\n",
    "            feature = np.zeros(shape=(need_rows,len(fe.feature_names())), dtype=np.float32)\n",
    "            idx = 0\n",
    "            for qid in fetch_later:\n",
    "                for doc in fe.get_result(qid):\n",
    "                    info[idx,0] = int(qid)\n",
    "                    info[idx,1] = int(doc['pid'])\n",
    "                    info[idx,2] = qidpid2rel[int(qid)][int(doc['pid'])]\n",
    "                    feature[idx,:] = doc['features']\n",
    "                    idx += 1\n",
    "            info = pd.DataFrame(info, columns=['qid','pid','rel'])\n",
    "            feature = pd.DataFrame(feature, columns=fe.feature_names())\n",
    "            df_pieces.append(pd.concat([info,feature], axis=1))\n",
    "            del info, feature\n",
    "            fetch_later = []\n",
    "            need_rows = 0\n",
    "    #deal with rest\n",
    "    if len(fetch_later) > 0:\n",
    "        info = np.zeros(shape=(need_rows,3), dtype=np.int32)\n",
    "        feature = np.zeros(shape=(need_rows,len(fe.feature_names())), dtype=np.float32)\n",
    "        idx = 0\n",
    "        for qid in fetch_later:\n",
    "            for doc in fe.get_result(qid):\n",
    "                info[idx,0] = int(qid)\n",
    "                info[idx,1] = int(doc['pid'])\n",
    "                info[idx,2] = qidpid2rel[int(qid)][int(doc['pid'])]\n",
    "                feature[idx,:] = doc['features']\n",
    "                idx += 1\n",
    "        info = pd.DataFrame(info, columns=['qid','pid','rel'])\n",
    "        feature = pd.DataFrame(feature, columns=fe.feature_names())\n",
    "        df_pieces.append(pd.concat([info,feature], axis=1))\n",
    "        del info, feature\n",
    "    data = pd.concat(df_pieces, axis=0, ignore_index=True)\n",
    "    del df_pieces\n",
    "    data = data.sort_values(by='qid', kind='mergesort')\n",
    "    group = data.groupby('qid').agg(count=('pid', 'count'))['count']\n",
    "    return data,group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:37:36.410569Z",
     "start_time": "2020-12-24T05:37:36.375085Z"
    }
   },
   "outputs": [],
   "source": [
    "def hash_df(df):\n",
    "    h = pd.util.hash_pandas_object(df)\n",
    "    return hex(h.sum().astype(np.uint64))\n",
    "\n",
    "\n",
    "def hash_anserini_jar():\n",
    "    find = glob.glob(os.environ['ANSERINI_CLASSPATH'] + \"/*fatjar.jar\")\n",
    "    assert len(find) == 1\n",
    "    md5Hash = hashlib.md5(open(find[0], 'rb').read())\n",
    "    return md5Hash.hexdigest()\n",
    "\n",
    "\n",
    "def hash_fe(fe):\n",
    "    return hashlib.md5(','.join(sorted(fe.feature_names())).encode()).hexdigest()\n",
    "\n",
    "\n",
    "def data_loader(task, df, queries, fe):\n",
    "    df_hash = hash_df(df)\n",
    "    jar_hash = hash_anserini_jar()\n",
    "    fe_hash = hash_fe(fe)\n",
    "    if os.path.exists(f'{task}_{df_hash}_{jar_hash}_{fe_hash}.pickle'):\n",
    "        res = pickle.load(open(f'{task}_{df_hash}_{jar_hash}_{fe_hash}.pickle','rb'))\n",
    "        print(res['data'].shape)\n",
    "        print(res['data'].qid.drop_duplicates().shape)\n",
    "        print(res['group'].mean())\n",
    "        print(res['data'].head(10))\n",
    "        print(res['data'].info())\n",
    "        return res\n",
    "    else:\n",
    "        if task == 'train' or task == 'dev': \n",
    "            data,group = extract(df, queries, fe)\n",
    "            obj = {'data':data,'group':group,'df_hash':df_hash,'jar_hash':jar_hash,'fe_hash':fe_hash}\n",
    "            print(data.shape)\n",
    "            print(data.qid.drop_duplicates().shape)\n",
    "            print(group.mean())\n",
    "            print(data.head(10))\n",
    "            print(data.info())\n",
    "            pickle.dump(obj,open(f'{task}_{df_hash}_{jar_hash}_{fe_hash}.pickle','wb'))\n",
    "            return obj\n",
    "        else:\n",
    "            raise Exception('unknown parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:37:36.425215Z",
     "start_time": "2020-12-24T05:37:36.414188Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def export(df, fn):\n",
    "    with open(fn,'w') as f:\n",
    "        line_num = 0\n",
    "        for qid, group in tqdm(df.groupby('qid')):\n",
    "            line = {}\n",
    "            line['qid'] = qid\n",
    "            line['docIds'] = [str(did) for did in group.reset_index().pid.drop_duplicates().tolist()]\n",
    "            assert 'qid' not in queries[str(qid)]\n",
    "            assert 'docIds' not in queries[str(qid)]\n",
    "            line.update(queries[str(qid)])\n",
    "            f.write(json.dumps(line)+'\\n')\n",
    "            line_num += 1\n",
    "            if line_num >= 1000:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:59:32.761683Z",
     "start_time": "2020-12-24T05:37:36.429365Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9907/400782 [00:29<11:12, 580.98it/s]"
     ]
    }
   ],
   "source": [
    "train_extracted = data_loader('train', sampled_train, queries, fe)\n",
    "# export(sampled_train, 'sampled_train_export.json')\n",
    "dev_extracted = data_loader('dev', dev, queries, fe)\n",
    "# export(dev, 'sampled_dev_export.json')\n",
    "del sampled_train, dev\n",
    "feature_name = fe.feature_names()\n",
    "del queries, fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T06:06:56.005832Z",
     "start_time": "2020-12-24T06:06:55.989321Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def eval_mrr(dev_data):\n",
    "    score_tie_counter = 0\n",
    "    score_tie_query = set()\n",
    "\n",
    "    MRR = []\n",
    "    for qid, group in tqdm(dev_data.groupby('qid')):\n",
    "        group = group.reset_index()\n",
    "        rank = 0\n",
    "        prev_score = None\n",
    "        assert len(group['pid'].tolist()) == len(set(group['pid'].tolist()))\n",
    "        # stable sort is also used in LightGBM\n",
    "\n",
    "        for t in group.sort_values('score', ascending=False, kind='mergesort').itertuples():\n",
    "            if prev_score is not None and abs(t.score - prev_score) < 1e-8:\n",
    "                score_tie_counter += 1\n",
    "                score_tie_query.add(qid)\n",
    "            prev_score = t.score\n",
    "            prev_pid = t.pid\n",
    "            rank += 1\n",
    "            if t.rel>0:\n",
    "                MRR.append(1.0/rank)\n",
    "                break\n",
    "            elif rank == 10 or rank == len(group):\n",
    "                MRR.append(0.)\n",
    "                break\n",
    "\n",
    "    score_tie = f'score_tie occurs {score_tie_counter} times in {len(score_tie_query)} queries'\n",
    "    print(score_tie,np.mean(MRR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T06:06:56.344013Z",
     "start_time": "2020-12-24T06:06:56.321800Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_recall(dev_qrel, dev_data):\n",
    "    dev_rel_num = dev_qrel[dev_qrel['rel']>0].groupby('qid').count()['rel']\n",
    "\n",
    "    score_tie_counter = 0\n",
    "    score_tie_query = set()\n",
    "    \n",
    "    recall_point = [10,20,50,100,200,500,1000]\n",
    "    recall_curve = {k:[] for k in recall_point}\n",
    "    for qid, group in tqdm(dev_data.groupby('qid')):\n",
    "        group = group.reset_index()\n",
    "        rank = 0\n",
    "        prev_score = None\n",
    "        assert len(group['pid'].tolist()) == len(set(group['pid'].tolist()))\n",
    "        # stable sort is also used in LightGBM\n",
    "        total_rel = dev_rel_num.loc[qid]\n",
    "        query_recall = [0 for k in recall_point]\n",
    "        for t in group.sort_values('score', ascending=False, kind='mergesort').itertuples():\n",
    "            if prev_score is not None and abs(t.score - prev_score) < 1e-8:\n",
    "                score_tie_counter += 1\n",
    "                score_tie_query.add(qid)\n",
    "            prev_score = t.score\n",
    "            rank += 1\n",
    "            if t.rel>0:\n",
    "                for i,p in enumerate(recall_point):\n",
    "                    if rank <= p:\n",
    "                        query_recall[i] += 1\n",
    "        for i,p in enumerate(recall_point):\n",
    "            if total_rel>0:\n",
    "                recall_curve[p].append(query_recall[i]/total_rel)\n",
    "            else:\n",
    "                recall_curve[p].append(0.)\n",
    "\n",
    "    score_tie = f'score_tie occurs {score_tie_counter} times in {len(score_tie_query)} queries'\n",
    "    print(score_tie)\n",
    "    \n",
    "    for k,v in recall_curve.items():\n",
    "        avg = np.mean(v)\n",
    "        print(f'recall@{k}:{avg}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T06:07:52.125880Z",
     "start_time": "2020-12-24T06:06:57.077069Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_X = train_extracted['data'].loc[:, feature_name]\n",
    "train_Y = train_extracted['data']['rel']\n",
    "dev_X = dev_extracted['data'].loc[:, feature_name]\n",
    "dev_Y = dev_extracted['data']['rel']\n",
    "lgb_train = lgb.Dataset(train_X,label=train_Y,group=train_extracted['group'])\n",
    "lgb_valid = lgb.Dataset(dev_X,label=dev_Y,group=dev_extracted['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T06:07:52.402359Z",
     "start_time": "2020-12-24T06:07:52.141635Z"
    }
   },
   "outputs": [],
   "source": [
    "for i,n in enumerate(feature_name):\n",
    "    if np.isnan(train_X.iloc[:,i]).any():\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T06:08:13.572910Z",
     "start_time": "2020-12-24T06:07:52.405030Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_rel_num = dev_qrel[dev_qrel['rel']>0].groupby('qid').count()['rel']\n",
    "gid = 0\n",
    "sample_id = 0\n",
    "dev_group_rel_num = []\n",
    "for qid,group in dev_extracted['data'].groupby('qid'):\n",
    "    group = group.sort_values(['pid'])\n",
    "    assert len(group) == dev_extracted['group'].iloc[gid]\n",
    "    assert np.isclose(group.iloc[0,:].loc[feature_name],\n",
    "                      dev_X.iloc[sample_id,:], equal_nan=True).all()\n",
    "    dev_group_rel_num.append(dev_rel_num.loc[qid])\n",
    "    gid += 1\n",
    "    sample_id += len(group)\n",
    "dev_group = dev_extracted['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T06:08:13.580008Z",
     "start_time": "2020-12-24T06:08:13.575211Z"
    }
   },
   "outputs": [],
   "source": [
    "def recall_at_200(preds, dataset):\n",
    "    global dev_group_rel_num\n",
    "    global dev_group\n",
    "    labels = dataset.get_label()\n",
    "    groups = dataset.get_group()\n",
    "    assert np.equal(groups, dev_group).all()\n",
    "    idx = 0\n",
    "    recall = 0\n",
    "    for g,gnum in zip(groups, dev_group_rel_num):\n",
    "        top_preds = labels[idx:idx+g][np.argsort(preds[idx:idx+g])]\n",
    "        recall += np.sum(top_preds[-200:])/gnum\n",
    "        idx += g\n",
    "    assert idx == len(preds)\n",
    "    return 'recall@200', recall/len(groups), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T06:12:46.484607Z",
     "start_time": "2020-12-24T06:08:13.581992Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dev_extracted['data']['score'] = 0.\n",
    "for seed in [12345]:\n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'lambdarank',\n",
    "            'max_bin':255,\n",
    "            'num_leaves':63,\n",
    "            'max_depth':-1,\n",
    "            'min_data_in_leaf':50,\n",
    "            'min_sum_hessian_in_leaf':0,\n",
    "#             'bagging_fraction':0.8,\n",
    "#             'bagging_freq':50,\n",
    "            'feature_fraction':1,\n",
    "            'learning_rate':0.1,\n",
    "            'num_boost_round':1000,\n",
    "            'early_stopping_round':200,\n",
    "            'metric':'custom',\n",
    "            'label_gain':[0,1],\n",
    "            'lambdarank_truncation_level':20,\n",
    "            'seed':seed,\n",
    "            'num_threads':max(multiprocessing.cpu_count()//2,1)\n",
    "    }\n",
    "    num_boost_round = params.pop('num_boost_round')\n",
    "    early_stopping_round = params.pop('early_stopping_round')\n",
    "    gbm = lgb.train(params, lgb_train,\n",
    "                    valid_sets=lgb_valid,\n",
    "                    num_boost_round=num_boost_round,\n",
    "                    early_stopping_rounds=early_stopping_round,\n",
    "                    feval=recall_at_200,\n",
    "                    feature_name=feature_name,\n",
    "                    verbose_eval=True)\n",
    "    dev_extracted['data']['score'] += gbm.predict(dev_X)\n",
    "    best_score = gbm.best_score['valid_0']['recall@200']\n",
    "    print(best_score)\n",
    "    best_iteration = gbm.best_iteration\n",
    "    print(best_iteration)\n",
    "    feature_importances = sorted(list(zip(feature_name,gbm.feature_importance().tolist())),\n",
    "                                 key=lambda x:x[1],reverse=True)\n",
    "    print(feature_importances)\n",
    "eval_recall(dev_qrel, dev_extracted['data'])\n",
    "eval_mrr(dev_extracted['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ANSERINI_CLASSPATH'] = \"../../anserini/target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
