{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T15:09:12.590322Z",
     "start_time": "2020-11-16T15:09:01.216878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32429423, 1)\n",
      "(327721,)\n",
      "rel    98.954364\n",
      "dtype: float64\n",
      "            rel\n",
      "qid pid        \n",
      "91  30491     0\n",
      "    40677     0\n",
      "    228542    0\n",
      "    315007    0\n",
      "    412769    0\n",
      "    492641    0\n",
      "    517618    0\n",
      "    745919    0\n",
      "    777051    0\n",
      "    793527    1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 32429423 entries, (91, 30491) to (1185869, 8822597)\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   rel     int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 592.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from collections import defaultdict\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "from pyserini.ltr import *\n",
    "from pyserini.search import get_topics_with_reader\n",
    "\n",
    "def train_data_loader(neg_sample=30, random_seed=12345):\n",
    "    if os.path.exists(f'train_sampled_with_{neg_sample}_{random_seed}.pickle'):\n",
    "        sampled_train = pd.read_pickle(f'train_sampled_with_{neg_sample}_{random_seed}.pickle')\n",
    "        print(sampled_train.shape)\n",
    "        print(sampled_train.index.get_level_values('qid').drop_duplicates().shape)\n",
    "        print(sampled_train.groupby('qid').count().mean())\n",
    "        print(sampled_train.head(10))\n",
    "        print(sampled_train.info())\n",
    "        return sampled_train\n",
    "    else:\n",
    "        train = pd.read_csv('collections/msmarco-passage/qidpidtriples.train.full.tsv', sep=\"\\t\",\n",
    "                            names=['qid', 'pos_pid', 'neg_pid'], dtype=np.int32)\n",
    "        pos_half = train[['qid', 'pos_pid']].rename(columns={\"pos_pid\": \"pid\"}).drop_duplicates()\n",
    "        pos_half['rel'] = np.int32(1)\n",
    "        neg_half = train[['qid', 'neg_pid']].rename(columns={\"neg_pid\": \"pid\"}).drop_duplicates()\n",
    "        neg_half['rel'] = np.int32(0)\n",
    "        del train\n",
    "        sampled_neg_half = []\n",
    "        for qid, group in tqdm(neg_half.groupby('qid')):\n",
    "            sampled_neg_half.append(group.sample(n=min(neg_sample, len(group)), random_state=random_seed))\n",
    "        sampled_train = pd.concat([pos_half] + sampled_neg_half, axis=0, ignore_index=True)\n",
    "        sampled_train = sampled_train.sort_values(['qid','pid']).set_index(['qid','pid'])\n",
    "        print(sampled_train.shape)\n",
    "        print(sampled_train.index.get_level_values('qid').drop_duplicates().shape)\n",
    "        print(sampled_train.groupby('qid').count().mean())\n",
    "        print(sampled_train.head(10))\n",
    "        print(sampled_train.info())\n",
    "\n",
    "        sampled_train.to_pickle(f'train_sampled_with_{neg_sample}_{random_seed}.pickle')\n",
    "        return sampled_train\n",
    "sampled_train = train_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T15:09:13.778516Z",
     "start_time": "2020-11-16T15:09:12.592660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6668967, 1)\n",
      "(6980,)\n",
      "rel    955.439398\n",
      "dtype: float64\n",
      "            rel\n",
      "qid pid        \n",
      "2   10749     0\n",
      "    63138     0\n",
      "    96198     0\n",
      "    98589     0\n",
      "    98595     0\n",
      "    112123    0\n",
      "    112127    0\n",
      "    112128    0\n",
      "    112130    0\n",
      "    112131    0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 6668967 entries, (2, 10749) to (1102400, 8837328)\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   rel     int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 253.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def dev_data_loader(task='rerank'):\n",
    "    if os.path.exists(f'dev_{task}.pickle'):\n",
    "        dev = pd.read_pickle(f'dev_{task}.pickle')\n",
    "        print(dev.shape)\n",
    "        print(dev.index.get_level_values('qid').drop_duplicates().shape)\n",
    "        print(dev.groupby('qid').count().mean())\n",
    "        print(dev.head(10))\n",
    "        print(dev.info())\n",
    "        return dev\n",
    "    else:\n",
    "        if task == 'rerank':\n",
    "            dev = pd.read_csv('collections/msmarco-passage/top1000.dev', sep=\"\\t\",\n",
    "                              names=['qid', 'pid', 'query', 'doc'], usecols=['qid', 'pid'], dtype=np.int32)\n",
    "        elif task == 'anserini':\n",
    "            dev = pd.read_csv('runs/msmarco-passage/run.msmarco-passage.dev.small.tsv',sep=\"\\t\",\n",
    "                            names=['qid','pid','rank'], dtype=np.int32)\n",
    "        else:\n",
    "            raise Exception('unknown parameters')\n",
    "        dev_qrel = pd.read_csv('collections/msmarco-passage/qrels.dev.small.tsv', sep=\"\\t\",\n",
    "                               names=[\"qid\", \"q0\", \"pid\", \"rel\"], usecols=['qid', 'pid', 'rel'], dtype=np.int32)\n",
    "        dev = dev.merge(dev_qrel, left_on=['qid', 'pid'], right_on=['qid', 'pid'], how='left')\n",
    "        dev['rel'] = dev['rel'].fillna(0).astype(np.int32)\n",
    "        dev = dev.sort_values(['qid','pid']).set_index(['qid','pid'])\n",
    "        \n",
    "        print(dev.shape)\n",
    "        print(dev.index.get_level_values('qid').drop_duplicates().shape)\n",
    "        print(dev.groupby('qid').count().mean())\n",
    "        print(dev.head(10))\n",
    "        print(dev.info())\n",
    "\n",
    "        dev.to_pickle(f'dev_{task}.pickle')\n",
    "        return dev\n",
    "dev = dev_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T15:09:18.104410Z",
     "start_time": "2020-11-16T15:09:13.780745Z"
    }
   },
   "outputs": [],
   "source": [
    "def query_loader(choice='default'):\n",
    "    if os.path.exists(f'query_{choice}_tokenized.pickle'):\n",
    "        return pickle.load(open(f'query_{choice}_tokenized.pickle','rb'))\n",
    "    else:\n",
    "        if choice == 'default':\n",
    "            analyzer = Analyzer(get_lucene_analyzer())\n",
    "            queries = get_topics_with_reader('io.anserini.search.topicreader.TsvIntTopicReader', \\\n",
    "                                             'collections/msmarco-passage/queries.train.tsv')\n",
    "            queries.update(get_topics_with_reader('io.anserini.search.topicreader.TsvIntTopicReader', \\\n",
    "                                                  'collections/msmarco-passage/queries.dev.tsv'))\n",
    "            for qid,value in queries.items():\n",
    "                assert 'tokenized' not in value\n",
    "                value['tokenized'] = analyzer.analyze(value['title'])\n",
    "        else:\n",
    "            raise Exception('unknown parameters')\n",
    "\n",
    "        pickle.dump(queries,open(f'query_{choice}_tokenized.pickle','wb'))\n",
    "\n",
    "        return queries\n",
    "queries = query_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T15:09:19.584983Z",
     "start_time": "2020-11-16T15:09:18.106763Z"
    }
   },
   "outputs": [],
   "source": [
    "fe = FeatureExtractor('indexes/msmarco-passage/lucene-index-msmarco/',max(multiprocessing.cpu_count()//2,1))\n",
    "fe.add(BM25(k1=0.9,b=0.4))\n",
    "fe.add(BM25(k1=1.2,b=0.75))\n",
    "fe.add(BM25(k1=2.0,b=0.75))\n",
    "fe.add(LMDir(mu=1000))\n",
    "fe.add(LMDir(mu=1500))\n",
    "fe.add(LMDir(mu=2500))\n",
    "fe.add(LMJM(0.1))\n",
    "fe.add(LMJM(0.4))\n",
    "fe.add(LMJM(0.7))\n",
    "fe.add(DFR_GL2())\n",
    "fe.add(DFR_In_expB2())\n",
    "fe.add(DPH())\n",
    "fe.add(Proximity())\n",
    "fe.add(DocSize())\n",
    "fe.add(QueryLength())\n",
    "fe.add(UniqueTermCount())\n",
    "fe.add(MatchingTermCount())\n",
    "fe.add(QueryCoverageRatio())\n",
    "fe.add(SCS())\n",
    "fe.add(tfStat(AvgPooler()))\n",
    "fe.add(tfStat(SumPooler()))\n",
    "fe.add(tfStat(MinPooler()))\n",
    "fe.add(tfStat(MaxPooler()))\n",
    "fe.add(tfStat(VarPooler()))\n",
    "fe.add(tfIdfStat(AvgPooler()))\n",
    "fe.add(tfIdfStat(SumPooler()))\n",
    "fe.add(tfIdfStat(MinPooler()))\n",
    "fe.add(tfIdfStat(MaxPooler()))\n",
    "fe.add(tfIdfStat(VarPooler()))\n",
    "fe.add(normalizedTfStat(AvgPooler()))\n",
    "fe.add(normalizedTfStat(SumPooler()))\n",
    "fe.add(normalizedTfStat(MinPooler()))\n",
    "fe.add(normalizedTfStat(MaxPooler()))\n",
    "fe.add(normalizedTfStat(VarPooler()))\n",
    "fe.add(idfStat(AvgPooler()))\n",
    "fe.add(idfStat(SumPooler()))\n",
    "fe.add(idfStat(MinPooler()))\n",
    "fe.add(idfStat(MaxPooler()))\n",
    "fe.add(idfStat(VarPooler()))\n",
    "fe.add(ictfStat(AvgPooler()))\n",
    "fe.add(ictfStat(SumPooler()))\n",
    "fe.add(ictfStat(MinPooler()))\n",
    "fe.add(ictfStat(MaxPooler()))\n",
    "fe.add(ictfStat(VarPooler()))\n",
    "fe.add(scqStat(AvgPooler()))\n",
    "fe.add(scqStat(SumPooler()))\n",
    "fe.add(scqStat(MinPooler()))\n",
    "fe.add(scqStat(MaxPooler()))\n",
    "fe.add(scqStat(VarPooler()))\n",
    "fe.add(UnorderedSequentialPairs(3))\n",
    "fe.add(UnorderedSequentialPairs(8))\n",
    "fe.add(UnorderedSequentialPairs(15))\n",
    "fe.add(OrderedSequentialPairs(3))\n",
    "fe.add(OrderedSequentialPairs(8))\n",
    "fe.add(OrderedSequentialPairs(15))\n",
    "fe.add(UnorderedQueryPairs(3))\n",
    "fe.add(UnorderedQueryPairs(8))\n",
    "fe.add(UnorderedQueryPairs(15))\n",
    "fe.add(OrderedQueryPairs(3))\n",
    "fe.add(OrderedQueryPairs(8))\n",
    "fe.add(OrderedQueryPairs(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T15:09:19.598514Z",
     "start_time": "2020-11-16T15:09:19.586935Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract(df, queries, fe):\n",
    "    df_pieces = []\n",
    "    fetch_later = []\n",
    "    qidpid2rel = defaultdict(dict)\n",
    "    need_rows = 0\n",
    "    for qid,group in tqdm(df.groupby('qid')):\n",
    "        for t in group.reset_index().itertuples():\n",
    "            assert t.pid not in qidpid2rel[t.qid]\n",
    "            qidpid2rel[t.qid][t.pid] = t.rel\n",
    "            need_rows += 1\n",
    "        fe.lazy_extract(str(qid),queries[qid]['tokenized'],list(qidpid2rel[t.qid].keys()))\n",
    "        fetch_later.append(str(qid))\n",
    "        if len(fetch_later) == 10000:\n",
    "            info = np.zeros(shape=(need_rows,3), dtype=np.int32)\n",
    "            feature = np.zeros(shape=(need_rows,len(fe.feature_names())), dtype=np.float32)\n",
    "            idx = 0\n",
    "            for qid in fetch_later:\n",
    "                for doc in fe.get_result(qid):\n",
    "                    info[idx,0] = int(qid)\n",
    "                    info[idx,1] = int(doc['pid'])\n",
    "                    info[idx,2] = qidpid2rel[int(qid)][int(doc['pid'])]\n",
    "                    feature[idx,:] = doc['features']\n",
    "                    idx += 1\n",
    "            info = pd.DataFrame(info, columns=['qid','pid','rel'])\n",
    "            feature = pd.DataFrame(feature, columns=fe.feature_names())\n",
    "            df_pieces.append(pd.concat([info,feature], axis=1))\n",
    "            fetch_later = []\n",
    "            need_rows = 0\n",
    "    #deal with rest\n",
    "    if len(fetch_later) > 0:\n",
    "        info = np.zeros(shape=(need_rows,3), dtype=np.int32)\n",
    "        feature = np.zeros(shape=(need_rows,len(fe.feature_names())), dtype=np.float32)\n",
    "        idx = 0\n",
    "        for qid in fetch_later:\n",
    "            for doc in fe.get_result(qid):\n",
    "                info[idx,0] = int(qid)\n",
    "                info[idx,1] = int(doc['pid'])\n",
    "                info[idx,2] = qidpid2rel[int(qid)][int(doc['pid'])]\n",
    "                feature[idx,:] = doc['features']\n",
    "                idx += 1\n",
    "        info = pd.DataFrame(info, columns=['qid','pid','rel'])\n",
    "        feature = pd.DataFrame(feature, columns=fe.feature_names())\n",
    "        df_pieces.append(pd.concat([info,feature], axis=1))\n",
    "    data = pd.concat(df_pieces, axis=0, ignore_index=True)\n",
    "    data = data.sort_values(by='qid', kind='mergesort')\n",
    "    group = data.groupby('qid').agg(count=('pid', 'count'))['count']\n",
    "    return data,group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T15:09:19.619647Z",
     "start_time": "2020-11-16T15:09:19.601056Z"
    }
   },
   "outputs": [],
   "source": [
    "def hash_df(df):\n",
    "    h = pd.util.hash_pandas_object(df)\n",
    "    return hex(h.sum().astype(np.uint64))\n",
    "\n",
    "\n",
    "def hash_anserini_jar():\n",
    "    find = glob.glob(os.environ['ANSERINI_CLASSPATH'] + \"/*fatjar.jar\")\n",
    "    assert len(find) == 1\n",
    "    md5Hash = hashlib.md5(open(find[0], 'rb').read())\n",
    "    return md5Hash.hexdigest()\n",
    "\n",
    "\n",
    "def hash_fe(fe):\n",
    "    return hashlib.md5(','.join(sorted(fe.feature_names())).encode()).hexdigest()\n",
    "\n",
    "\n",
    "def data_loader(task, df, queries, fe):\n",
    "    df_hash = hash_df(df)\n",
    "    jar_hash = hash_anserini_jar()\n",
    "    fe_hash = hash_fe(fe)\n",
    "    if os.path.exists(f'{task}_{df_hash}_{jar_hash}_{fe_hash}.pickle'):\n",
    "        res = pickle.load(open(f'{task}_{df_hash}_{jar_hash}_{fe_hash}.pickle','rb'))\n",
    "        print(res['data'].shape)\n",
    "        print(res['data'].qid.drop_duplicates().shape)\n",
    "        print(res['group'].mean())\n",
    "        print(res['data'].head(10))\n",
    "        print(res['data'].info())\n",
    "        return res\n",
    "    else:\n",
    "        if task == 'train' or task == 'dev': \n",
    "            data,group = extract(df, queries, fe)\n",
    "            obj = {'data':data,'group':group,'df_hash':df_hash,'jar_hash':jar_hash,'fe_hash':fe_hash}\n",
    "            print(data.shape)\n",
    "            print(data.qid.drop_duplicates().shape)\n",
    "            print(group.mean())\n",
    "            print(data.head(10))\n",
    "            print(data.info())\n",
    "            pickle.dump(obj,open(f'{task}_{df_hash}_{jar_hash}_{fe_hash}.pickle','wb'))\n",
    "            return obj\n",
    "        else:\n",
    "            raise Exception('unknown parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T15:09:48.529440Z",
     "start_time": "2020-11-16T15:09:19.621995Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32429423, 64)\n",
      "(327721,)\n",
      "98.95436362027456\n",
      "   qid     pid  rel  BM25_k1_0.90_b_0.40  BM25_k1_1.20_b_0.75  \\\n",
      "0   91   30491    0            14.489719            15.415164   \n",
      "1   91   40677    0            20.184231            22.359982   \n",
      "2   91  228542    0            21.023039            22.106380   \n",
      "3   91  315007    0            14.996305            14.801217   \n",
      "4   91  412769    0            21.192341            20.946251   \n",
      "5   91  492641    0            12.471210            12.869027   \n",
      "6   91  517618    0            21.082029            22.528090   \n",
      "7   91  745919    0            25.917801            26.662256   \n",
      "8   91  777051    0            16.559290            17.715590   \n",
      "9   91  793527    1            36.255280            37.489307   \n",
      "\n",
      "   BM25_k1_2.00_b_0.75  LMD_mu_1000  LMD_mu_1500  LMD_mu_2500  \\\n",
      "0            18.494238     9.712474    10.429009    11.322591   \n",
      "1            25.231373    18.332842    19.348846    20.545277   \n",
      "2            23.523069    25.236155    26.379995    27.667492   \n",
      "3            15.892462    17.574730    18.361660    19.264788   \n",
      "4            20.846048    32.466148    33.655209    34.946541   \n",
      "5            14.335307    11.481089    12.146570    12.935162   \n",
      "6            24.303537    25.299299    26.379938    27.579916   \n",
      "7            31.012358    21.170097    22.424141    23.953951   \n",
      "8            19.886635    17.733826    18.587194    19.557175   \n",
      "9            42.093887    34.407925    36.330475    38.600681   \n",
      "\n",
      "   LMJM_lambda_0.10  ...  UnorderedSequentialPairs15  OrderedSequentialPairs3  \\\n",
      "0          4.764418  ...                         0.0                      0.0   \n",
      "1          8.122877  ...                         0.0                      0.0   \n",
      "2         13.250860  ...                         3.0                      1.0   \n",
      "3         10.536425  ...                         1.0                      1.0   \n",
      "4         19.200148  ...                         1.0                      0.0   \n",
      "5          5.989919  ...                         0.0                      0.0   \n",
      "6         13.179546  ...                         0.0                      0.0   \n",
      "7         11.847783  ...                         4.0                      0.0   \n",
      "8          8.946726  ...                         2.0                      0.0   \n",
      "9         17.976955  ...                        21.0                      4.0   \n",
      "\n",
      "   OrderedSequentialPairs8  OrderedSequentialPairs15  UnorderedQueryPairs3  \\\n",
      "0                      0.0                       0.0                   0.0   \n",
      "1                      0.0                       0.0                   0.0   \n",
      "2                      1.0                       2.0                   1.0   \n",
      "3                      1.0                       1.0                   2.0   \n",
      "4                      0.0                       0.0                   0.0   \n",
      "5                      0.0                       0.0                   0.0   \n",
      "6                      0.0                       0.0                   0.0   \n",
      "7                      0.0                       1.0                   5.0   \n",
      "8                      1.0                       1.0                   0.0   \n",
      "9                      5.0                      12.0                  12.0   \n",
      "\n",
      "   UnorderedQueryPairs8  UnorderedQueryPairs15  OrderedQueryPairs3  \\\n",
      "0                   6.0                   10.0                 0.0   \n",
      "1                   2.0                    6.0                 0.0   \n",
      "2                   5.0                   11.0                 1.0   \n",
      "3                   2.0                    2.0                 2.0   \n",
      "4                   3.0                    3.0                 0.0   \n",
      "5                   0.0                    0.0                 0.0   \n",
      "6                   2.0                    4.0                 0.0   \n",
      "7                  15.0                   39.0                 2.0   \n",
      "8                   2.0                    4.0                 0.0   \n",
      "9                  21.0                   59.0                 6.0   \n",
      "\n",
      "   OrderedQueryPairs8  OrderedQueryPairs15  \n",
      "0                 3.0                  5.0  \n",
      "1                 0.0                  2.0  \n",
      "2                 3.0                  6.0  \n",
      "3                 2.0                  2.0  \n",
      "4                 1.0                  1.0  \n",
      "5                 0.0                  0.0  \n",
      "6                 1.0                  2.0  \n",
      "7                 7.0                 19.0  \n",
      "8                 1.0                  2.0  \n",
      "9                 8.0                 28.0  \n",
      "\n",
      "[10 rows x 64 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32429423 entries, 0 to 32429422\n",
      "Data columns (total 64 columns):\n",
      " #   Column                      Dtype  \n",
      "---  ------                      -----  \n",
      " 0   qid                         int32  \n",
      " 1   pid                         int32  \n",
      " 2   rel                         int32  \n",
      " 3   BM25_k1_0.90_b_0.40         float32\n",
      " 4   BM25_k1_1.20_b_0.75         float32\n",
      " 5   BM25_k1_2.00_b_0.75         float32\n",
      " 6   LMD_mu_1000                 float32\n",
      " 7   LMD_mu_1500                 float32\n",
      " 8   LMD_mu_2500                 float32\n",
      " 9   LMJM_lambda_0.10            float32\n",
      " 10  LMJM_lambda_0.40            float32\n",
      " 11  LMJM_lambda_0.70            float32\n",
      " 12  DFR_GL2                     float32\n",
      " 13  DFR_In_expB2                float32\n",
      " 14  DPH                         float32\n",
      " 15  Proximity                   float32\n",
      " 16  DocSize                     float32\n",
      " 17  QueryLength                 float32\n",
      " 18  UniqueQueryTerms            float32\n",
      " 19  MatchingTermCount           float32\n",
      " 20  QueryCoverageRatio          float32\n",
      " 21  SCS                         float32\n",
      " 22  TFavg                       float32\n",
      " 23  TFsum                       float32\n",
      " 24  TFmin                       float32\n",
      " 25  TFmax                       float32\n",
      " 26  TFvar                       float32\n",
      " 27  TFIDFavg                    float32\n",
      " 28  TFIDFsum                    float32\n",
      " 29  TFIDFmin                    float32\n",
      " 30  TFIDFmax                    float32\n",
      " 31  TFIDFvar                    float32\n",
      " 32  NormalizedTFavg             float32\n",
      " 33  NormalizedTFsum             float32\n",
      " 34  NormalizedTFmin             float32\n",
      " 35  NormalizedTFmax             float32\n",
      " 36  NormalizedTFvar             float32\n",
      " 37  IDFavg                      float32\n",
      " 38  IDFsum                      float32\n",
      " 39  IDFmin                      float32\n",
      " 40  IDFmax                      float32\n",
      " 41  IDFvar                      float32\n",
      " 42  ICTFavg                     float32\n",
      " 43  ICTFsum                     float32\n",
      " 44  ICTFmin                     float32\n",
      " 45  ICTFmax                     float32\n",
      " 46  ICTFvar                     float32\n",
      " 47  SCQavg                      float32\n",
      " 48  SCQsum                      float32\n",
      " 49  SCQmin                      float32\n",
      " 50  SCQmax                      float32\n",
      " 51  SCQvar                      float32\n",
      " 52  UnorderedSequentialPairs3   float32\n",
      " 53  UnorderedSequentialPairs8   float32\n",
      " 54  UnorderedSequentialPairs15  float32\n",
      " 55  OrderedSequentialPairs3     float32\n",
      " 56  OrderedSequentialPairs8     float32\n",
      " 57  OrderedSequentialPairs15    float32\n",
      " 58  UnorderedQueryPairs3        float32\n",
      " 59  UnorderedQueryPairs8        float32\n",
      " 60  UnorderedQueryPairs15       float32\n",
      " 61  OrderedQueryPairs3          float32\n",
      " 62  OrderedQueryPairs8          float32\n",
      " 63  OrderedQueryPairs15         float32\n",
      "dtypes: float32(61), int32(3)\n",
      "memory usage: 8.0 GB\n",
      "None\n",
      "(6668967, 64)\n",
      "(6980,)\n",
      "955.4393982808023\n",
      "   qid     pid  rel  BM25_k1_0.90_b_0.40  BM25_k1_1.20_b_0.75  \\\n",
      "0    2   10749    0             8.842813             9.978682   \n",
      "1    2   63138    0             9.609193            10.731856   \n",
      "2    2   96198    0             8.728024             9.668857   \n",
      "3    2   98589    0            12.699286            14.042357   \n",
      "4    2   98595    0            11.181725            11.772854   \n",
      "5    2  112123    0            15.955744            17.375216   \n",
      "6    2  112127    0            21.200821            23.124138   \n",
      "7    2  112128    0             8.884659             9.361135   \n",
      "8    2  112130    0            18.646755            20.812979   \n",
      "9    2  112131    0            15.182899            15.518018   \n",
      "\n",
      "   BM25_k1_2.00_b_0.75  LMD_mu_1000  LMD_mu_1500  LMD_mu_2500  \\\n",
      "0            11.398603     6.202654     6.583692     7.055481   \n",
      "1            12.636791     5.813496     6.198410     6.679400   \n",
      "2            10.910498     6.206557     6.586314     7.057065   \n",
      "3            16.412817     5.837148     6.231281     6.731460   \n",
      "4            12.868898     6.249084     6.640071     7.136947   \n",
      "5            18.039532    13.791070    14.548838    15.487456   \n",
      "6            26.404234    12.051468    12.822822    13.791686   \n",
      "7             9.573666     6.930732     7.322369     7.817594   \n",
      "8            22.985289    13.097790    13.858706    14.802069   \n",
      "9            15.661107    13.810469    14.561901    15.495358   \n",
      "\n",
      "   LMJM_lambda_0.10  ...  UnorderedSequentialPairs15  OrderedSequentialPairs3  \\\n",
      "0          2.547617  ...                         0.0                      0.0   \n",
      "1          2.338880  ...                         0.0                      0.0   \n",
      "2          2.707944  ...                         0.0                      0.0   \n",
      "3          2.440727  ...                         0.0                      0.0   \n",
      "4          3.075758  ...                         0.0                      0.0   \n",
      "5          6.726688  ...                         1.0                      1.0   \n",
      "6          5.411838  ...                         6.0                      2.0   \n",
      "7          3.539322  ...                         0.0                      0.0   \n",
      "8          5.873483  ...                         1.0                      1.0   \n",
      "9          7.377446  ...                         1.0                      1.0   \n",
      "\n",
      "   OrderedSequentialPairs8  OrderedSequentialPairs15  UnorderedQueryPairs3  \\\n",
      "0                      0.0                       0.0                   0.0   \n",
      "1                      0.0                       0.0                   0.0   \n",
      "2                      0.0                       0.0                   0.0   \n",
      "3                      0.0                       0.0                   0.0   \n",
      "4                      0.0                       0.0                   0.0   \n",
      "5                      1.0                       1.0                   1.0   \n",
      "6                      3.0                       3.0                   3.0   \n",
      "7                      0.0                       0.0                   0.0   \n",
      "8                      1.0                       1.0                   1.0   \n",
      "9                      1.0                       1.0                   1.0   \n",
      "\n",
      "   UnorderedQueryPairs8  UnorderedQueryPairs15  OrderedQueryPairs3  \\\n",
      "0                   0.0                    0.0                 0.0   \n",
      "1                   0.0                    0.0                 0.0   \n",
      "2                   0.0                    0.0                 0.0   \n",
      "3                   0.0                    0.0                 0.0   \n",
      "4                   0.0                    0.0                 0.0   \n",
      "5                   1.0                    1.0                 1.0   \n",
      "6                   4.0                    6.0                 2.0   \n",
      "7                   0.0                    0.0                 0.0   \n",
      "8                   1.0                    1.0                 1.0   \n",
      "9                   1.0                    1.0                 1.0   \n",
      "\n",
      "   OrderedQueryPairs8  OrderedQueryPairs15  \n",
      "0                 0.0                  0.0  \n",
      "1                 0.0                  0.0  \n",
      "2                 0.0                  0.0  \n",
      "3                 0.0                  0.0  \n",
      "4                 0.0                  0.0  \n",
      "5                 1.0                  1.0  \n",
      "6                 3.0                  3.0  \n",
      "7                 0.0                  0.0  \n",
      "8                 1.0                  1.0  \n",
      "9                 1.0                  1.0  \n",
      "\n",
      "[10 rows x 64 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6668967 entries, 0 to 6668966\n",
      "Data columns (total 64 columns):\n",
      " #   Column                      Dtype  \n",
      "---  ------                      -----  \n",
      " 0   qid                         int32  \n",
      " 1   pid                         int32  \n",
      " 2   rel                         int32  \n",
      " 3   BM25_k1_0.90_b_0.40         float32\n",
      " 4   BM25_k1_1.20_b_0.75         float32\n",
      " 5   BM25_k1_2.00_b_0.75         float32\n",
      " 6   LMD_mu_1000                 float32\n",
      " 7   LMD_mu_1500                 float32\n",
      " 8   LMD_mu_2500                 float32\n",
      " 9   LMJM_lambda_0.10            float32\n",
      " 10  LMJM_lambda_0.40            float32\n",
      " 11  LMJM_lambda_0.70            float32\n",
      " 12  DFR_GL2                     float32\n",
      " 13  DFR_In_expB2                float32\n",
      " 14  DPH                         float32\n",
      " 15  Proximity                   float32\n",
      " 16  DocSize                     float32\n",
      " 17  QueryLength                 float32\n",
      " 18  UniqueQueryTerms            float32\n",
      " 19  MatchingTermCount           float32\n",
      " 20  QueryCoverageRatio          float32\n",
      " 21  SCS                         float32\n",
      " 22  TFavg                       float32\n",
      " 23  TFsum                       float32\n",
      " 24  TFmin                       float32\n",
      " 25  TFmax                       float32\n",
      " 26  TFvar                       float32\n",
      " 27  TFIDFavg                    float32\n",
      " 28  TFIDFsum                    float32\n",
      " 29  TFIDFmin                    float32\n",
      " 30  TFIDFmax                    float32\n",
      " 31  TFIDFvar                    float32\n",
      " 32  NormalizedTFavg             float32\n",
      " 33  NormalizedTFsum             float32\n",
      " 34  NormalizedTFmin             float32\n",
      " 35  NormalizedTFmax             float32\n",
      " 36  NormalizedTFvar             float32\n",
      " 37  IDFavg                      float32\n",
      " 38  IDFsum                      float32\n",
      " 39  IDFmin                      float32\n",
      " 40  IDFmax                      float32\n",
      " 41  IDFvar                      float32\n",
      " 42  ICTFavg                     float32\n",
      " 43  ICTFsum                     float32\n",
      " 44  ICTFmin                     float32\n",
      " 45  ICTFmax                     float32\n",
      " 46  ICTFvar                     float32\n",
      " 47  SCQavg                      float32\n",
      " 48  SCQsum                      float32\n",
      " 49  SCQmin                      float32\n",
      " 50  SCQmax                      float32\n",
      " 51  SCQvar                      float32\n",
      " 52  UnorderedSequentialPairs3   float32\n",
      " 53  UnorderedSequentialPairs8   float32\n",
      " 54  UnorderedSequentialPairs15  float32\n",
      " 55  OrderedSequentialPairs3     float32\n",
      " 56  OrderedSequentialPairs8     float32\n",
      " 57  OrderedSequentialPairs15    float32\n",
      " 58  UnorderedQueryPairs3        float32\n",
      " 59  UnorderedQueryPairs8        float32\n",
      " 60  UnorderedQueryPairs15       float32\n",
      " 61  OrderedQueryPairs3          float32\n",
      " 62  OrderedQueryPairs8          float32\n",
      " 63  OrderedQueryPairs15         float32\n",
      "dtypes: float32(61), int32(3)\n",
      "memory usage: 1.6 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_extracted = data_loader('train', sampled_train, queries, fe)\n",
    "dev_extracted = data_loader('dev', dev, queries, fe)\n",
    "del sampled_train, dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T15:10:08.454088Z",
     "start_time": "2020-11-16T15:09:48.531593Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_name = fe.feature_names()\n",
    "train_X = train_extracted['data'].loc[:, feature_name]\n",
    "train_Y = train_extracted['data']['rel']\n",
    "dev_X = dev_extracted['data'].loc[:, feature_name]\n",
    "dev_Y = dev_extracted['data']['rel']\n",
    "lgb_train = lgb.Dataset(train_X,label=train_Y,group=train_extracted['group'])\n",
    "lgb_valid = lgb.Dataset(dev_X,label=dev_Y,group=dev_extracted['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T15:10:08.478193Z",
     "start_time": "2020-11-16T15:10:08.456969Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def eval_mrr(dev_data):\n",
    "    score_tie_counter = 0\n",
    "    score_tie_query = set()\n",
    "\n",
    "    MRR = []\n",
    "    for qid, group in tqdm(dev_data.groupby('qid')):\n",
    "        group = group.reset_index()\n",
    "        rank = 0\n",
    "        prev_score = None\n",
    "        assert len(group['pid'].tolist()) == len(set(group['pid'].tolist()))\n",
    "        # stable sort is also used in LightGBM\n",
    "\n",
    "        for t in group.sort_values('score', ascending=False, kind='mergesort').itertuples():\n",
    "            if prev_score is not None and abs(t.score - prev_score) < 1e-8:\n",
    "                score_tie_counter += 1\n",
    "                score_tie_query.add(qid)\n",
    "            prev_score = t.score\n",
    "            prev_pid = t.pid\n",
    "            rank += 1\n",
    "            if t.rel>0:\n",
    "                MRR.append(1.0/rank)\n",
    "                break\n",
    "            elif rank == 10 or rank == len(group):\n",
    "                MRR.append(0.)\n",
    "                break\n",
    "\n",
    "    score_tie = f'score_tie occurs {score_tie_counter} times in {len(score_tie_query)} queries'\n",
    "    print(score_tie,np.mean(MRR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-16T15:10:22.806Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total groups: 327721, total data: 32429423\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.345941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9841\n",
      "[LightGBM] [Info] Number of data points in the train set: 32429423, number of used features: 55\n",
      "[LightGBM] [Info] Total groups: 6980, total data: 6668967\n",
      "0.38917278770788793\n",
      "873\n",
      "[('DFR_In_expB2', 2578), ('SCQvar', 2220), ('SCQavg', 2163), ('DocSize', 1971), ('IDFsum', 1889), ('NormalizedTFvar', 1870), ('NormalizedTFmin', 1696), ('TFIDFvar', 1623), ('SCQmax', 1613), ('SCQsum', 1563), ('TFIDFmax', 1562), ('NormalizedTFavg', 1529), ('Proximity', 1513), ('DFR_GL2', 1485), ('BM25_k1_2.00_b_0.75', 1405), ('TFvar', 1393), ('BM25_k1_0.90_b_0.40', 1305), ('LMD_mu_2500', 1272), ('TFIDFavg', 1237), ('TFIDFsum', 1167), ('SCS', 999), ('UnorderedQueryPairs15', 933), ('ICTFvar', 920), ('IDFavg', 891), ('IDFvar', 868), ('TFavg', 842), ('IDFmax', 837), ('BM25_k1_1.20_b_0.75', 832), ('ICTFavg', 827), ('ICTFmax', 824), ('UnorderedSequentialPairs15', 791), ('ICTFsum', 778), ('UnorderedQueryPairs8', 722), ('LMD_mu_1000', 716), ('UnorderedQueryPairs3', 709), ('TFsum', 683), ('OrderedQueryPairs15', 617), ('OrderedQueryPairs3', 615), ('LMD_mu_1500', 589), ('QueryCoverageRatio', 576), ('OrderedQueryPairs8', 554), ('OrderedSequentialPairs3', 522), ('MatchingTermCount', 498), ('LMJM_lambda_0.70', 491), ('UnorderedSequentialPairs8', 477), ('UnorderedSequentialPairs3', 470), ('NormalizedTFsum', 442), ('OrderedSequentialPairs8', 408), ('OrderedSequentialPairs15', 393), ('LMJM_lambda_0.10', 386), ('TFmax', 368), ('LMJM_lambda_0.40', 304), ('UniqueQueryTerms', 107), ('QueryLength', 65), ('DPH', 18), ('TFmin', 0), ('TFIDFmin', 0), ('NormalizedTFmax', 0), ('IDFmin', 0), ('ICTFmin', 0), ('SCQmin', 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6980/6980 [00:36<00:00, 192.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_tie occurs 936 times in 712 queries 0.21424682767089642\n",
      "[LightGBM] [Info] Total groups: 327721, total data: 32429423\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.322068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9841\n",
      "[LightGBM] [Info] Number of data points in the train set: 32429423, number of used features: 55\n",
      "[LightGBM] [Info] Total groups: 6980, total data: 6668967\n",
      "0.38958647913160804\n",
      "316\n",
      "[('DFR_In_expB2', 1170), ('IDFsum', 1004), ('SCQavg', 856), ('SCQsum', 746), ('NormalizedTFmin', 697), ('LMD_mu_2500', 676), ('NormalizedTFvar', 673), ('DocSize', 669), ('DFR_GL2', 633), ('SCQvar', 614), ('BM25_k1_0.90_b_0.40', 596), ('BM25_k1_2.00_b_0.75', 592), ('TFIDFvar', 591), ('TFIDFmax', 558), ('UnorderedQueryPairs15', 463), ('TFvar', 414), ('MatchingTermCount', 406), ('SCQmax', 404), ('NormalizedTFavg', 385), ('TFsum', 368), ('UnorderedQueryPairs3', 349), ('QueryCoverageRatio', 329), ('Proximity', 316), ('TFavg', 316), ('UnorderedSequentialPairs15', 315), ('UnorderedQueryPairs8', 315), ('OrderedSequentialPairs3', 294), ('OrderedQueryPairs3', 289), ('TFIDFsum', 278), ('OrderedQueryPairs8', 265), ('LMD_mu_1000', 262), ('BM25_k1_1.20_b_0.75', 251), ('TFIDFavg', 251), ('LMD_mu_1500', 226), ('OrderedQueryPairs15', 213), ('IDFavg', 207), ('IDFmax', 206), ('SCS', 202), ('ICTFsum', 202), ('IDFvar', 191), ('UnorderedSequentialPairs3', 188), ('ICTFmax', 169), ('ICTFvar', 161), ('LMJM_lambda_0.70', 160), ('TFmax', 153), ('ICTFavg', 153), ('UnorderedSequentialPairs8', 148), ('OrderedSequentialPairs8', 144), ('NormalizedTFsum', 134), ('LMJM_lambda_0.10', 124), ('OrderedSequentialPairs15', 117), ('LMJM_lambda_0.40', 108), ('QueryLength', 14), ('UniqueQueryTerms', 14), ('DPH', 13), ('TFmin', 0), ('TFIDFmin', 0), ('NormalizedTFmax', 0), ('IDFmin', 0), ('ICTFmin', 0), ('SCQmin', 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6980/6980 [00:39<00:00, 177.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_tie occurs 892 times in 699 queries 0.21428753354254784\n",
      "[LightGBM] [Info] Total groups: 327721, total data: 32429423\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.099861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9841\n",
      "[LightGBM] [Info] Number of data points in the train set: 32429423, number of used features: 55\n",
      "[LightGBM] [Info] Total groups: 6980, total data: 6668967\n",
      "0.3905145464744318\n",
      "472\n",
      "[('DFR_In_expB2', 1647), ('IDFsum', 1222), ('SCQavg', 1157), ('SCQvar', 1060), ('NormalizedTFmin', 993), ('DocSize', 975), ('SCQsum', 975), ('NormalizedTFvar', 939), ('TFIDFvar', 914), ('LMD_mu_2500', 897), ('BM25_k1_2.00_b_0.75', 861), ('DFR_GL2', 844), ('TFIDFmax', 819), ('BM25_k1_0.90_b_0.40', 817), ('TFvar', 710), ('NormalizedTFavg', 705), ('SCQmax', 704), ('UnorderedQueryPairs15', 642), ('Proximity', 636), ('TFIDFsum', 555), ('TFIDFavg', 502), ('TFavg', 497), ('TFsum', 476), ('UnorderedSequentialPairs15', 464), ('UnorderedQueryPairs8', 437), ('UnorderedQueryPairs3', 428), ('LMD_mu_1000', 410), ('MatchingTermCount', 407), ('IDFavg', 404), ('SCS', 396), ('ICTFsum', 389), ('BM25_k1_1.20_b_0.75', 386), ('OrderedSequentialPairs3', 359), ('OrderedQueryPairs3', 357), ('ICTFvar', 356), ('IDFvar', 355), ('IDFmax', 354), ('LMD_mu_1500', 352), ('QueryCoverageRatio', 349), ('ICTFmax', 348), ('OrderedQueryPairs8', 347), ('OrderedQueryPairs15', 345), ('ICTFavg', 339), ('UnorderedSequentialPairs3', 299), ('LMJM_lambda_0.70', 270), ('NormalizedTFsum', 263), ('OrderedSequentialPairs8', 241), ('LMJM_lambda_0.10', 221), ('UnorderedSequentialPairs8', 218), ('TFmax', 201), ('LMJM_lambda_0.40', 181), ('OrderedSequentialPairs15', 177), ('UniqueQueryTerms', 30), ('QueryLength', 23), ('DPH', 11), ('TFmin', 0), ('TFIDFmin', 0), ('NormalizedTFmax', 0), ('IDFmin', 0), ('ICTFmin', 0), ('SCQmin', 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6980/6980 [00:37<00:00, 185.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_tie occurs 873 times in 686 queries 0.2147775390003184\n",
      "[LightGBM] [Info] Total groups: 327721, total data: 32429423\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.174163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9841\n",
      "[LightGBM] [Info] Number of data points in the train set: 32429423, number of used features: 55\n",
      "[LightGBM] [Info] Total groups: 6980, total data: 6668967\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'lambdarank',\n",
    "    'max_bin':255,\n",
    "    'num_leaves':63,\n",
    "    'max_depth':10,\n",
    "    'min_data_in_leaf':50,\n",
    "    'min_sum_hessian_in_leaf':0,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq':20,\n",
    "    'feature_fraction':1,\n",
    "    'learning_rate':0.1,\n",
    "    'num_boost_round':1000,\n",
    "    'early_stopping_round':500,\n",
    "    'metric':['map'],\n",
    "    'eval_at':[10],\n",
    "    'label_gain':[0,1],\n",
    "    'lambdarank_truncation_level':20,\n",
    "    'num_threads':max(multiprocessing.cpu_count()//2,1)\n",
    "}\n",
    "num_boost_round = params.pop('num_boost_round')\n",
    "early_stopping_round = params.pop('early_stopping_round')\n",
    "eval_results={}\n",
    "dev_extracted['data']['score']=0.\n",
    "for seed in [12345,31345,21356,65743,68786]:\n",
    "    params['seed'] = seed\n",
    "    gbm = lgb.train(params, lgb_train, \n",
    "                    valid_sets=lgb_valid,\n",
    "                    num_boost_round=num_boost_round,\n",
    "                    early_stopping_rounds =early_stopping_round,\n",
    "                    feature_name=feature_name,\n",
    "                    evals_result=eval_results,\n",
    "                    verbose_eval=False)\n",
    "    dev_extracted['data']['score'] += gbm.predict(dev_X)\n",
    "    best_score = gbm.best_score['valid_0']['map@10']\n",
    "    print(best_score)\n",
    "    best_iteration = gbm.best_iteration\n",
    "    print(best_iteration)\n",
    "    eval_map = eval_results['valid_0']['map@10']\n",
    "    # print(eval_map)\n",
    "    feature_importances = sorted(list(zip(feature_name,gbm.feature_importance().tolist())),key=lambda x:x[1],reverse=True)\n",
    "    print(feature_importances)\n",
    "    eval_mrr(dev_extracted['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'lambdarank',\n",
    "    'max_bin':255,\n",
    "    'num_leaves':63,\n",
    "    'max_depth':10,\n",
    "    'min_data_in_leaf':50,\n",
    "    'min_sum_hessian_in_leaf':0,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq':50,\n",
    "    'feature_fraction':1,\n",
    "    'learning_rate':0.1,\n",
    "    'num_boost_round':500,\n",
    "    'metric':['map'],\n",
    "    'eval_at':[10],\n",
    "    'label_gain':[0,1],\n",
    "    'lambdarank_truncation_level':20,\n",
    "    'seed':12345,\n",
    "    'num_threads':max(multiprocessing.cpu_count()//2,1)\n",
    "}\n",
    "\n",
    "num_boost_round = params.pop('num_boost_round')\n",
    "eval_results={}\n",
    "cv_gbm = lgb.cv(params, lgb_train, nfold=5, \n",
    "                num_boost_round=num_boost_round,\n",
    "                feature_name=feature_name,\n",
    "                verbose_eval=False,\n",
    "                return_cvbooster=True)\n",
    "dev_extracted['data']['score'] = 0.\n",
    "for gbm in cv_gbm['cvbooster'].boosters:\n",
    "    dev_extracted['data']['score']+=gbm.predict(dev_X)\n",
    "feature_importances = sorted(list(zip(feature_name,gbm.feature_importance().tolist())),key=lambda x:x[1],reverse=True)\n",
    "print(feature_importances)\n",
    "eval_mrr(dev_extracted['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
