{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-05T06:05:41.271Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from collections import defaultdict\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "from pyserini.ltr import *\n",
    "from pyserini.search import get_topics_with_reader\n",
    "\n",
    "def train_data_loader(task='triple', neg_sample=10, random_seed=12345):\n",
    "    if os.path.exists(f'train_{task}_sampled_with_{neg_sample}_{random_seed}.pickle'):\n",
    "        sampled_train = pd.read_pickle(f'train_{task}_sampled_with_{neg_sample}_{random_seed}.pickle')\n",
    "        print(sampled_train.shape)\n",
    "        print(sampled_train.index.get_level_values('qid').drop_duplicates().shape)\n",
    "        print(sampled_train.groupby('qid').count().mean())\n",
    "        print(sampled_train.head(10))\n",
    "        print(sampled_train.info())\n",
    "        return sampled_train\n",
    "    else:\n",
    "        if task == 'triple':\n",
    "            train = pd.read_csv('collections/msmarco-passage/qidpidtriples.train.full.2.tsv', sep=\"\\t\",\n",
    "                                names=['qid', 'pos_pid', 'neg_pid'], dtype=np.int32)\n",
    "            pos_half = train[['qid', 'pos_pid']].rename(columns={\"pos_pid\": \"pid\"}).drop_duplicates()\n",
    "            pos_half['rel'] = np.int32(1)\n",
    "            neg_half = train[['qid', 'neg_pid']].rename(columns={\"neg_pid\": \"pid\"}).drop_duplicates()\n",
    "            neg_half['rel'] = np.int32(0)\n",
    "            del train\n",
    "            sampled_neg_half = []\n",
    "            for qid, group in tqdm(neg_half.groupby('qid')):\n",
    "                sampled_neg_half.append(group.sample(n=min(neg_sample, len(group)), random_state=random_seed))\n",
    "            sampled_train = pd.concat([pos_half] + sampled_neg_half, axis=0, ignore_index=True)\n",
    "            sampled_train = sampled_train.sort_values(['qid','pid']).set_index(['qid','pid'])\n",
    "            print(sampled_train.shape)\n",
    "            print(sampled_train.index.get_level_values('qid').drop_duplicates().shape)\n",
    "            print(sampled_train.groupby('qid').count().mean())\n",
    "            print(sampled_train.head(10))\n",
    "            print(sampled_train.info())\n",
    "\n",
    "            sampled_train.to_pickle(f'train_{task}_sampled_with_{neg_sample}_{random_seed}.pickle')\n",
    "        elif task == 'rank':\n",
    "            qrel = defaultdict(list)\n",
    "            with open(\"collections/msmarco-passage/qrels.train.tsv\") as f:\n",
    "                for line in f:\n",
    "                    topicid, _, docid, rel = line.strip().split('\\t')\n",
    "                    assert rel == \"1\", line.split(' ')\n",
    "                    qrel[topicid].append(docid)\n",
    "            \n",
    "            qid2pos = defaultdict(list)\n",
    "            qid2neg = defaultdict(list)\n",
    "            with open(\"runs/msmarco-passage/run.train.small.tsv\") as f:\n",
    "                for line in tqdm(f):\n",
    "                    topicid, docid, rank = line.split()\n",
    "                    assert topicid in qrel\n",
    "                    if docid in qrel[topicid]:\n",
    "                        qid2pos[topicid].append(docid)\n",
    "                    else:\n",
    "                        qid2neg[topicid].append(docid)\n",
    "            sampled_train = []\n",
    "            for topicid, pos_list in tqdm(qid2pos.items()):\n",
    "                neg_list = random.sample(qid2neg[topicid], min(len(qid2neg[topicid]), neg_sample))\n",
    "                for positive_docid in pos_list:\n",
    "                    sampled_train.append((int(topicid), int(positive_docid), 1))\n",
    "                for negative_docid in neg_list:\n",
    "                    sampled_train.append((int(topicid), int(negative_docid), 0))\n",
    "            sampled_train = pd.DataFrame(sampled_train,columns=['qid','pid','rel'],dtype=np.int32)\n",
    "            sampled_train = sampled_train.sort_values(['qid','pid']).set_index(['qid','pid'])\n",
    "            print(sampled_train.shape)\n",
    "            print(sampled_train.index.get_level_values('qid').drop_duplicates().shape)\n",
    "            print(sampled_train.groupby('qid').count().mean())\n",
    "            print(sampled_train.head(10))\n",
    "            print(sampled_train.info())\n",
    "\n",
    "            sampled_train.to_pickle(f'train_{task}_sampled_with_{neg_sample}_{random_seed}.pickle')\n",
    "        else:\n",
    "            raise Exception('unknown parameters')\n",
    "        return sampled_train\n",
    "sampled_train = train_data_loader(task='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-05T06:05:41.273Z"
    }
   },
   "outputs": [],
   "source": [
    "def dev_data_loader(task='anserini'):\n",
    "    if os.path.exists(f'dev_{task}.pickle'):\n",
    "        dev = pd.read_pickle(f'dev_{task}.pickle')\n",
    "        print(dev.shape)\n",
    "        print(dev.index.get_level_values('qid').drop_duplicates().shape)\n",
    "        print(dev.groupby('qid').count().mean())\n",
    "        print(dev.head(10))\n",
    "        print(dev.info())\n",
    "        return dev\n",
    "    else:\n",
    "        if task == 'rerank':\n",
    "            dev = pd.read_csv('collections/msmarco-passage/top1000.dev', sep=\"\\t\",\n",
    "                              names=['qid', 'pid', 'query', 'doc'], usecols=['qid', 'pid'], dtype=np.int32)\n",
    "        elif task == 'anserini':\n",
    "            dev = pd.read_csv('runs/msmarco-passage/run.msmarco-passage.dev.small.tsv',sep=\"\\t\",\n",
    "                            names=['qid','pid','rank'], dtype=np.int32)\n",
    "        elif task == 'pygaggle':\n",
    "            dev = pd.read_csv('../pygaggle/data/msmarco_ans_entire/run.dev.small.tsv',sep=\"\\t\",\n",
    "                            names=['qid','pid','rank'], dtype=np.int32)\n",
    "        else:\n",
    "            raise Exception('unknown parameters')\n",
    "        dev_qrel = pd.read_csv('collections/msmarco-passage/qrels.dev.small.tsv', sep=\"\\t\",\n",
    "                               names=[\"qid\", \"q0\", \"pid\", \"rel\"], usecols=['qid', 'pid', 'rel'], dtype=np.int32)\n",
    "        dev = dev.merge(dev_qrel, left_on=['qid', 'pid'], right_on=['qid', 'pid'], how='left')\n",
    "        dev['rel'] = dev['rel'].fillna(0).astype(np.int32)\n",
    "        dev = dev.sort_values(['qid','pid']).set_index(['qid','pid'])\n",
    "        \n",
    "        print(dev.shape)\n",
    "        print(dev.index.get_level_values('qid').drop_duplicates().shape)\n",
    "        print(dev.groupby('qid').count().mean())\n",
    "        print(dev.head(10))\n",
    "        print(dev.info())\n",
    "\n",
    "        dev.to_pickle(f'dev_{task}.pickle')\n",
    "        return dev\n",
    "dev = dev_data_loader(task='anserini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-05T06:05:41.275Z"
    }
   },
   "outputs": [],
   "source": [
    "def query_loader(choice='default'):\n",
    "    if os.path.exists(f'query_{choice}_tokenized.pickle'):\n",
    "        return pickle.load(open(f'query_{choice}_tokenized.pickle','rb'))\n",
    "    else:\n",
    "        if choice == 'default':\n",
    "            analyzer = Analyzer(get_lucene_analyzer())\n",
    "            nonStopAnalyzer = Analyzer(get_lucene_analyzer(stopwords=False))\n",
    "            queries = get_topics_with_reader('io.anserini.search.topicreader.TsvIntTopicReader', \\\n",
    "                                             'collections/msmarco-passage/queries.train.tsv')\n",
    "            queries.update(get_topics_with_reader('io.anserini.search.topicreader.TsvIntTopicReader', \\\n",
    "                                                  'collections/msmarco-passage/queries.dev.tsv'))\n",
    "            for qid,value in queries.items():\n",
    "                assert 'tokenized' not in value\n",
    "                value['tokenized'] = analyzer.analyze(value['title'])\n",
    "                assert 'nonSW' not in value\n",
    "                value['nonSW'] = nonStopAnalyzer.analyze(value['title'])\n",
    "        else:\n",
    "            raise Exception('unknown parameters')\n",
    "\n",
    "        pickle.dump(queries,open(f'query_{choice}_tokenized.pickle','wb'))\n",
    "\n",
    "        return queries\n",
    "queries = query_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:21:58.708834Z",
     "start_time": "2020-12-05T06:21:58.631619Z"
    }
   },
   "outputs": [],
   "source": [
    "fe = FeatureExtractor('indexes/msmarco-passage/lucene-index-msmarco/',max(multiprocessing.cpu_count()//2,1))\n",
    "fe.add(BM25(k1=0.9,b=0.4))\n",
    "fe.add(BM25(k1=1.2,b=0.75))\n",
    "fe.add(BM25(k1=2.0,b=0.75))\n",
    "\n",
    "fe.add(LMDir(mu=1000))\n",
    "fe.add(LMDir(mu=1500))\n",
    "fe.add(LMDir(mu=2500))\n",
    "\n",
    "fe.add(LMJM(0.1))\n",
    "fe.add(LMJM(0.4))\n",
    "fe.add(LMJM(0.7))\n",
    "\n",
    "fe.add(NTFIDF())\n",
    "fe.add(ProbalitySum())\n",
    "\n",
    "fe.add(DFR_GL2())\n",
    "fe.add(DFR_In_expB2())\n",
    "fe.add(DPH())\n",
    "\n",
    "# fe.add(ContextDFR_GL2(AvgPooler()))\n",
    "# fe.add(ContextDFR_GL2(VarPooler()))\n",
    "# fe.add(ContextDFR_In_expB2(AvgPooler()))\n",
    "# fe.add(ContextDFR_In_expB2(VarPooler()))\n",
    "# fe.add(ContextDPH(AvgPooler()))\n",
    "# fe.add(ContextDPH(VarPooler()))\n",
    "\n",
    "fe.add(Proximity())\n",
    "fe.add(TPscore())\n",
    "fe.add(tpDist())\n",
    "# fe.add(SDM())\n",
    "\n",
    "fe.add(DocSize())\n",
    "fe.add(Entropy())\n",
    "fe.add(StopCover())\n",
    "fe.add(StopRatio())\n",
    "\n",
    "fe.add(QueryLength())\n",
    "fe.add(QueryLengthNonStopWords())\n",
    "fe.add(QueryCoverageRatio())\n",
    "fe.add(UniqueTermCount())\n",
    "fe.add(MatchingTermCount())\n",
    "fe.add(SCS())\n",
    "\n",
    "fe.add(tfStat(AvgPooler()))\n",
    "fe.add(tfStat(SumPooler()))\n",
    "fe.add(tfStat(MinPooler()))\n",
    "fe.add(tfStat(MaxPooler()))\n",
    "fe.add(tfStat(VarPooler()))\n",
    "fe.add(tfIdfStat(AvgPooler()))\n",
    "fe.add(tfIdfStat(SumPooler()))\n",
    "fe.add(tfIdfStat(MinPooler()))\n",
    "fe.add(tfIdfStat(MaxPooler()))\n",
    "fe.add(tfIdfStat(VarPooler()))\n",
    "fe.add(scqStat(AvgPooler()))\n",
    "fe.add(scqStat(SumPooler()))\n",
    "fe.add(scqStat(MinPooler()))\n",
    "fe.add(scqStat(MaxPooler()))\n",
    "fe.add(scqStat(VarPooler()))\n",
    "fe.add(normalizedTfStat(AvgPooler()))\n",
    "fe.add(normalizedTfStat(SumPooler()))\n",
    "fe.add(normalizedTfStat(MinPooler()))\n",
    "fe.add(normalizedTfStat(MaxPooler()))\n",
    "fe.add(normalizedTfStat(VarPooler()))\n",
    "# fe.add(normalizedDocSizeStat(AvgPooler()))\n",
    "# fe.add(normalizedDocSizeStat(SumPooler()))\n",
    "# fe.add(normalizedDocSizeStat(MinPooler()))\n",
    "# fe.add(normalizedDocSizeStat(MaxPooler()))\n",
    "# fe.add(normalizedDocSizeStat(VarPooler()))\n",
    "\n",
    "fe.add(idfStat(AvgPooler()))\n",
    "fe.add(idfStat(SumPooler()))\n",
    "fe.add(idfStat(MinPooler()))\n",
    "fe.add(idfStat(MaxPooler()))\n",
    "fe.add(idfStat(VarPooler()))\n",
    "fe.add(idfStat(MaxMinRatioPooler()))\n",
    "fe.add(idfStat(ConfidencePooler()))\n",
    "fe.add(ictfStat(AvgPooler()))\n",
    "fe.add(ictfStat(SumPooler()))\n",
    "fe.add(ictfStat(MinPooler()))\n",
    "fe.add(ictfStat(MaxPooler()))\n",
    "fe.add(ictfStat(VarPooler()))\n",
    "fe.add(ictfStat(MaxMinRatioPooler()))\n",
    "fe.add(ictfStat(ConfidencePooler()))\n",
    "\n",
    "fe.add(UnorderedSequentialPairs(3))\n",
    "fe.add(UnorderedSequentialPairs(8))\n",
    "fe.add(UnorderedSequentialPairs(15))\n",
    "fe.add(OrderedSequentialPairs(3))\n",
    "fe.add(OrderedSequentialPairs(8))\n",
    "fe.add(OrderedSequentialPairs(15))\n",
    "fe.add(UnorderedQueryPairs(3))\n",
    "fe.add(UnorderedQueryPairs(8))\n",
    "fe.add(UnorderedQueryPairs(15))\n",
    "fe.add(OrderedQueryPairs(3))\n",
    "fe.add(OrderedQueryPairs(8))\n",
    "fe.add(OrderedQueryPairs(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:21:59.401627Z",
     "start_time": "2020-12-05T06:21:59.377007Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract(df, queries, fe):\n",
    "    df_pieces = []\n",
    "    fetch_later = []\n",
    "    qidpid2rel = defaultdict(dict)\n",
    "    need_rows = 0\n",
    "    for qid,group in tqdm(df.groupby('qid')):\n",
    "        for t in group.reset_index().itertuples():\n",
    "            assert t.pid not in qidpid2rel[t.qid]\n",
    "            qidpid2rel[t.qid][t.pid] = t.rel\n",
    "            need_rows += 1\n",
    "        fe.lazy_extract(str(qid),queries[qid]['nonSW'], queries[qid]['tokenized'],list(qidpid2rel[t.qid].keys()))\n",
    "        fetch_later.append(str(qid))\n",
    "        if len(fetch_later) == 10000:\n",
    "            info = np.zeros(shape=(need_rows,3), dtype=np.int32)\n",
    "            feature = np.zeros(shape=(need_rows,len(fe.feature_names())), dtype=np.float32)\n",
    "            idx = 0\n",
    "            for qid in fetch_later:\n",
    "                for doc in fe.get_result(qid):\n",
    "                    info[idx,0] = int(qid)\n",
    "                    info[idx,1] = int(doc['pid'])\n",
    "                    info[idx,2] = qidpid2rel[int(qid)][int(doc['pid'])]\n",
    "                    feature[idx,:] = doc['features']\n",
    "                    idx += 1\n",
    "            info = pd.DataFrame(info, columns=['qid','pid','rel'])\n",
    "            feature = pd.DataFrame(feature, columns=fe.feature_names())\n",
    "            df_pieces.append(pd.concat([info,feature], axis=1))\n",
    "            fetch_later = []\n",
    "            need_rows = 0\n",
    "    #deal with rest\n",
    "    if len(fetch_later) > 0:\n",
    "        info = np.zeros(shape=(need_rows,3), dtype=np.int32)\n",
    "        feature = np.zeros(shape=(need_rows,len(fe.feature_names())), dtype=np.float32)\n",
    "        idx = 0\n",
    "        for qid in fetch_later:\n",
    "            for doc in fe.get_result(qid):\n",
    "                info[idx,0] = int(qid)\n",
    "                info[idx,1] = int(doc['pid'])\n",
    "                info[idx,2] = qidpid2rel[int(qid)][int(doc['pid'])]\n",
    "                feature[idx,:] = doc['features']\n",
    "                idx += 1\n",
    "        info = pd.DataFrame(info, columns=['qid','pid','rel'])\n",
    "        feature = pd.DataFrame(feature, columns=fe.feature_names())\n",
    "        df_pieces.append(pd.concat([info,feature], axis=1))\n",
    "    data = pd.concat(df_pieces, axis=0, ignore_index=True)\n",
    "    data = data.sort_values(by='qid', kind='mergesort')\n",
    "    group = data.groupby('qid').agg(count=('pid', 'count'))['count']\n",
    "    return data,group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:21:59.737010Z",
     "start_time": "2020-12-05T06:21:59.716809Z"
    }
   },
   "outputs": [],
   "source": [
    "def hash_df(df):\n",
    "    h = pd.util.hash_pandas_object(df)\n",
    "    return hex(h.sum().astype(np.uint64))\n",
    "\n",
    "\n",
    "def hash_anserini_jar():\n",
    "    find = glob.glob(os.environ['ANSERINI_CLASSPATH'] + \"/*fatjar.jar\")\n",
    "    assert len(find) == 1\n",
    "    md5Hash = hashlib.md5(open(find[0], 'rb').read())\n",
    "    return md5Hash.hexdigest()\n",
    "\n",
    "\n",
    "def hash_fe(fe):\n",
    "    return hashlib.md5(','.join(sorted(fe.feature_names())).encode()).hexdigest()\n",
    "\n",
    "\n",
    "def data_loader(task, df, queries, fe):\n",
    "    df_hash = hash_df(df)\n",
    "    jar_hash = hash_anserini_jar()\n",
    "    fe_hash = hash_fe(fe)\n",
    "    if os.path.exists(f'{task}_{df_hash}_{jar_hash}_{fe_hash}.pickle'):\n",
    "        res = pickle.load(open(f'{task}_{df_hash}_{jar_hash}_{fe_hash}.pickle','rb'))\n",
    "        print(res['data'].shape)\n",
    "        print(res['data'].qid.drop_duplicates().shape)\n",
    "        print(res['group'].mean())\n",
    "        print(res['data'].head(10))\n",
    "        print(res['data'].info())\n",
    "        return res\n",
    "    else:\n",
    "        if task == 'train' or task == 'dev': \n",
    "            data,group = extract(df, queries, fe)\n",
    "            obj = {'data':data,'group':group,'df_hash':df_hash,'jar_hash':jar_hash,'fe_hash':fe_hash}\n",
    "            print(data.shape)\n",
    "            print(data.qid.drop_duplicates().shape)\n",
    "            print(group.mean())\n",
    "            print(data.head(10))\n",
    "            print(data.info())\n",
    "            pickle.dump(obj,open(f'{task}_{df_hash}_{jar_hash}_{fe_hash}.pickle','wb'))\n",
    "            return obj\n",
    "        else:\n",
    "            raise Exception('unknown parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:22:00.318679Z",
     "start_time": "2020-12-05T06:22:00.308504Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def export(df, fn):\n",
    "    with open(fn,'w') as f:\n",
    "        for qid, group in tqdm(df.groupby('qid')):\n",
    "            line = {}\n",
    "            line['qid'] = qid\n",
    "            line['queryTokens'] = queries[qid]['tokenized']\n",
    "            line['queryText'] = queries[qid]['nonSW']\n",
    "            line['docIds'] = [str(did) for did in group.reset_index().pid.drop_duplicates().tolist()]\n",
    "            f.write(json.dumps(line)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:27:57.647993Z",
     "start_time": "2020-12-05T06:22:00.946763Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4770762, 76)\n",
      "(431848,)\n",
      "11.04731757470221\n",
      "   qid      pid  rel  contents_BM25_k1_0.90_b_0.40  \\\n",
      "0    3    23817    0                     19.794847   \n",
      "1    3  1142680    1                     26.467836   \n",
      "2    3  1887104    0                     19.061369   \n",
      "3    3  2679073    0                     13.294892   \n",
      "4    3  2724793    0                     24.698397   \n",
      "5    3  3060834    0                     30.585629   \n",
      "6    3  6151998    0                     24.326681   \n",
      "7    3  7099153    0                     15.369918   \n",
      "8    3  8073992    0                     19.706621   \n",
      "9    3  8150773    0                     13.005863   \n",
      "\n",
      "   contents_BM25_k1_1.20_b_0.75  contents_BM25_k1_2.00_b_0.75  \\\n",
      "0                     19.961182                     20.695307   \n",
      "1                     27.822981                     32.060062   \n",
      "2                     20.757126                     21.550747   \n",
      "3                     13.668623                     13.829547   \n",
      "4                     26.857327                     30.772301   \n",
      "5                     32.052269                     37.090504   \n",
      "6                     25.374958                     28.182550   \n",
      "7                     15.614080                     17.212532   \n",
      "8                     22.311905                     26.546478   \n",
      "9                     14.362500                     15.010633   \n",
      "\n",
      "   contents_LMD_mu_1000  contents_LMD_mu_1500  contents_LMD_mu_2500  \\\n",
      "0            -33.428307            -34.427948            -35.638557   \n",
      "1            -30.457207            -31.519070            -32.854885   \n",
      "2            -34.024410            -35.043633            -36.262177   \n",
      "3            -35.678726            -36.373417            -37.236401   \n",
      "4            -31.669600            -32.718422            -34.005478   \n",
      "5            -29.366041            -30.552420            -32.015472   \n",
      "6            -31.539827            -32.608665            -33.942482   \n",
      "7            -35.187534            -35.811848            -36.587872   \n",
      "8            -33.511150            -34.261681            -35.210209   \n",
      "9            -36.402309            -37.064163            -37.858646   \n",
      "\n",
      "   contents_LMJM_lambda_0.10  ...  contents_UnorderedSequentialPairs_15  \\\n",
      "0                 -29.031923  ...                                   2.0   \n",
      "1                 -26.552271  ...                                  11.0   \n",
      "2                 -28.216408  ...                                   2.0   \n",
      "3                 -36.046192  ...                                   1.0   \n",
      "4                 -26.536318  ...                                  10.0   \n",
      "5                 -21.663504  ...                                  19.0   \n",
      "6                 -27.155710  ...                                   7.0   \n",
      "7                 -36.466312  ...                                   0.0   \n",
      "8                 -33.094772  ...                                   6.0   \n",
      "9                 -36.194874  ...                                   0.0   \n",
      "\n",
      "   contents_OrderedSequentialPairs_3  contents_OrderedSequentialPairs_8  \\\n",
      "0                                0.0                                0.0   \n",
      "1                                3.0                                4.0   \n",
      "2                                2.0                                2.0   \n",
      "3                                1.0                                1.0   \n",
      "4                                3.0                                4.0   \n",
      "5                                7.0                                9.0   \n",
      "6                                4.0                                4.0   \n",
      "7                                0.0                                0.0   \n",
      "8                                2.0                                3.0   \n",
      "9                                0.0                                0.0   \n",
      "\n",
      "   contents_OrderedSequentialPairs_15  contents_UnorderedQueryPairs_3  \\\n",
      "0                                 1.0                             0.0   \n",
      "1                                 6.0                             4.0   \n",
      "2                                 2.0                             3.0   \n",
      "3                                 1.0                             1.0   \n",
      "4                                 5.0                             7.0   \n",
      "5                                12.0                            11.0   \n",
      "6                                 6.0                             5.0   \n",
      "7                                 0.0                             0.0   \n",
      "8                                 4.0                             2.0   \n",
      "9                                 0.0                             0.0   \n",
      "\n",
      "   contents_UnorderedQueryPairs_8  contents_UnorderedQueryPairs_15  \\\n",
      "0                             2.0                              3.0   \n",
      "1                            10.0                             14.0   \n",
      "2                             3.0                              3.0   \n",
      "3                             1.0                              1.0   \n",
      "4                             9.0                             12.0   \n",
      "5                            20.0                             29.0   \n",
      "6                             6.0                              9.0   \n",
      "7                             1.0                              2.0   \n",
      "8                             4.0                              6.0   \n",
      "9                             0.0                              0.0   \n",
      "\n",
      "   contents_OrderedQueryPairs_3  contents_OrderedQueryPairs_8  \\\n",
      "0                           0.0                           1.0   \n",
      "1                           4.0                           6.0   \n",
      "2                           3.0                           3.0   \n",
      "3                           1.0                           1.0   \n",
      "4                           4.0                           5.0   \n",
      "5                          10.0                          13.0   \n",
      "6                           5.0                           5.0   \n",
      "7                           0.0                           1.0   \n",
      "8                           2.0                           3.0   \n",
      "9                           0.0                           0.0   \n",
      "\n",
      "   contents_OrderedQueryPairs_15  \n",
      "0                            2.0  \n",
      "1                            9.0  \n",
      "2                            3.0  \n",
      "3                            1.0  \n",
      "4                            6.0  \n",
      "5                           18.0  \n",
      "6                            8.0  \n",
      "7                            2.0  \n",
      "8                            4.0  \n",
      "9                            0.0  \n",
      "\n",
      "[10 rows x 76 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4770762 entries, 0 to 4770761\n",
      "Data columns (total 76 columns):\n",
      " #   Column                                Dtype  \n",
      "---  ------                                -----  \n",
      " 0   qid                                   int32  \n",
      " 1   pid                                   int32  \n",
      " 2   rel                                   int32  \n",
      " 3   contents_BM25_k1_0.90_b_0.40          float32\n",
      " 4   contents_BM25_k1_1.20_b_0.75          float32\n",
      " 5   contents_BM25_k1_2.00_b_0.75          float32\n",
      " 6   contents_LMD_mu_1000                  float32\n",
      " 7   contents_LMD_mu_1500                  float32\n",
      " 8   contents_LMD_mu_2500                  float32\n",
      " 9   contents_LMJM_lambda_0.10             float32\n",
      " 10  contents_LMJM_lambda_0.40             float32\n",
      " 11  contents_LMJM_lambda_0.70             float32\n",
      " 12  contents_NTFIDF                       float32\n",
      " 13  contents_Prob                         float32\n",
      " 14  contents_DFR_GL2                      float32\n",
      " 15  contents_DFR_In_expB2                 float32\n",
      " 16  contents_DPH                          float32\n",
      " 17  contents_Proximity                    float32\n",
      " 18  contents_TPscore                      float32\n",
      " 19  contents_tpDistWindow100              float32\n",
      " 20  contents_DocSize                      float32\n",
      " 21  Entropy                               float32\n",
      " 22  StopCover                             float32\n",
      " 23  StopRatio                             float32\n",
      " 24  QueryLength                           float32\n",
      " 25  QueryLengthNonStopWords               float32\n",
      " 26  contents_QueryCoverageRatio           float32\n",
      " 27  UniqueQueryTerms                      float32\n",
      " 28  contents_MatchingTermCount            float32\n",
      " 29  contents_SCS                          float32\n",
      " 30  contents_TF_avg                       float32\n",
      " 31  contents_TF_sum                       float32\n",
      " 32  contents_TF_min                       float32\n",
      " 33  contents_TF_max                       float32\n",
      " 34  contents_TF_var                       float32\n",
      " 35  contents_TFIDF_avg                    float32\n",
      " 36  contents_TFIDF_sum                    float32\n",
      " 37  contents_TFIDF_min                    float32\n",
      " 38  contents_TFIDF_max                    float32\n",
      " 39  contents_TFIDF_var                    float32\n",
      " 40  contents_SCQ_avg                      float32\n",
      " 41  contents_SCQ_sum                      float32\n",
      " 42  contents_SCQ_min                      float32\n",
      " 43  contents_SCQ_max                      float32\n",
      " 44  contents_SCQ_var                      float32\n",
      " 45  contents_NormalizedTF_avg             float32\n",
      " 46  contents_NormalizedTF_sum             float32\n",
      " 47  contents_NormalizedTF_min             float32\n",
      " 48  contents_NormalizedTF_max             float32\n",
      " 49  contents_NormalizedTF_var             float32\n",
      " 50  contents_IDF_avg                      float32\n",
      " 51  contents_IDF_sum                      float32\n",
      " 52  contents_IDF_min                      float32\n",
      " 53  contents_IDF_max                      float32\n",
      " 54  contents_IDF_var                      float32\n",
      " 55  contents_IDF_maxminratio              float32\n",
      " 56  contents_IDF_confidence               float32\n",
      " 57  contents_ICTF_avg                     float32\n",
      " 58  contents_ICTF_sum                     float32\n",
      " 59  contents_ICTF_min                     float32\n",
      " 60  contents_ICTF_max                     float32\n",
      " 61  contents_ICTF_var                     float32\n",
      " 62  contents_ICTF_maxminratio             float32\n",
      " 63  contents_ICTF_confidence              float32\n",
      " 64  contents_UnorderedSequentialPairs_3   float32\n",
      " 65  contents_UnorderedSequentialPairs_8   float32\n",
      " 66  contents_UnorderedSequentialPairs_15  float32\n",
      " 67  contents_OrderedSequentialPairs_3     float32\n",
      " 68  contents_OrderedSequentialPairs_8     float32\n",
      " 69  contents_OrderedSequentialPairs_15    float32\n",
      " 70  contents_UnorderedQueryPairs_3        float32\n",
      " 71  contents_UnorderedQueryPairs_8        float32\n",
      " 72  contents_UnorderedQueryPairs_15       float32\n",
      " 73  contents_OrderedQueryPairs_3          float32\n",
      " 74  contents_OrderedQueryPairs_8          float32\n",
      " 75  contents_OrderedQueryPairs_15         float32\n",
      "dtypes: float32(73), int32(3)\n",
      "memory usage: 1.4 GB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6980/6980 [00:53<00:00, 129.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6974598, 76)\n",
      "(6980,)\n",
      "999.2260744985673\n",
      "   qid     pid  rel  contents_BM25_k1_0.90_b_0.40  \\\n",
      "0    2   55860    0                     12.348820   \n",
      "1    2   72202    0                     10.927653   \n",
      "2    2   72210    0                     13.675473   \n",
      "3    2   98589    0                     12.699286   \n",
      "4    2   98590    0                     12.492470   \n",
      "5    2   98593    0                     11.077914   \n",
      "6    2   98595    0                     11.181725   \n",
      "7    2  112123    0                     15.955744   \n",
      "8    2  112126    0                     11.468307   \n",
      "9    2  112127    0                     21.200821   \n",
      "\n",
      "   contents_BM25_k1_1.20_b_0.75  contents_BM25_k1_2.00_b_0.75  \\\n",
      "0                     13.151269                     14.964364   \n",
      "1                     11.041017                     11.088634   \n",
      "2                     13.716912                     14.579938   \n",
      "3                     14.042357                     16.412817   \n",
      "4                     13.508439                     15.535631   \n",
      "5                     11.527296                     12.512784   \n",
      "6                     11.772854                     12.868898   \n",
      "7                     17.375216                     18.039532   \n",
      "8                     12.481902                     13.925775   \n",
      "9                     23.124138                     26.404234   \n",
      "\n",
      "   contents_LMD_mu_1000  contents_LMD_mu_1500  contents_LMD_mu_2500  \\\n",
      "0            -23.447887            -23.810581            -24.285263   \n",
      "1            -25.348633            -25.968309            -26.691536   \n",
      "2            -24.175011            -24.847307            -25.665592   \n",
      "3            -23.413172            -23.787159            -24.271072   \n",
      "4            -23.433472            -23.800844            -24.279358   \n",
      "5            -23.849216            -24.212214            -24.686415   \n",
      "6            -23.840567            -24.206371            -24.682871   \n",
      "7            -21.773283            -22.522568            -23.454348   \n",
      "8            -23.817379            -24.190737            -24.673403   \n",
      "9            -20.040480            -20.801128            -21.761345   \n",
      "\n",
      "   contents_LMJM_lambda_0.10  ...  contents_UnorderedSequentialPairs_15  \\\n",
      "0                 -24.888071  ...                                   0.0   \n",
      "1                 -21.576532  ...                                   1.0   \n",
      "2                 -20.818115  ...                                   2.0   \n",
      "3                 -24.560862  ...                                   0.0   \n",
      "4                 -24.764460  ...                                   0.0   \n",
      "5                 -25.270000  ...                                   0.0   \n",
      "6                 -25.195894  ...                                   0.0   \n",
      "7                 -16.985819  ...                                   1.0   \n",
      "8                 -24.966324  ...                                   0.0   \n",
      "9                 -15.670968  ...                                   6.0   \n",
      "\n",
      "   contents_OrderedSequentialPairs_3  contents_OrderedSequentialPairs_8  \\\n",
      "0                                0.0                                0.0   \n",
      "1                                0.0                                0.0   \n",
      "2                                0.0                                0.0   \n",
      "3                                0.0                                0.0   \n",
      "4                                0.0                                0.0   \n",
      "5                                0.0                                0.0   \n",
      "6                                0.0                                0.0   \n",
      "7                                1.0                                1.0   \n",
      "8                                0.0                                0.0   \n",
      "9                                2.0                                3.0   \n",
      "\n",
      "   contents_OrderedSequentialPairs_15  contents_UnorderedQueryPairs_3  \\\n",
      "0                                 0.0                             0.0   \n",
      "1                                 0.0                             0.0   \n",
      "2                                 0.0                             0.0   \n",
      "3                                 0.0                             0.0   \n",
      "4                                 0.0                             0.0   \n",
      "5                                 0.0                             0.0   \n",
      "6                                 0.0                             0.0   \n",
      "7                                 1.0                             1.0   \n",
      "8                                 0.0                             0.0   \n",
      "9                                 3.0                             3.0   \n",
      "\n",
      "   contents_UnorderedQueryPairs_8  contents_UnorderedQueryPairs_15  \\\n",
      "0                             0.0                              0.0   \n",
      "1                             0.0                              1.0   \n",
      "2                             0.0                              2.0   \n",
      "3                             0.0                              0.0   \n",
      "4                             0.0                              0.0   \n",
      "5                             0.0                              0.0   \n",
      "6                             0.0                              0.0   \n",
      "7                             1.0                              1.0   \n",
      "8                             0.0                              0.0   \n",
      "9                             4.0                              6.0   \n",
      "\n",
      "   contents_OrderedQueryPairs_3  contents_OrderedQueryPairs_8  \\\n",
      "0                           0.0                           0.0   \n",
      "1                           0.0                           0.0   \n",
      "2                           0.0                           0.0   \n",
      "3                           0.0                           0.0   \n",
      "4                           0.0                           0.0   \n",
      "5                           0.0                           0.0   \n",
      "6                           0.0                           0.0   \n",
      "7                           1.0                           1.0   \n",
      "8                           0.0                           0.0   \n",
      "9                           2.0                           3.0   \n",
      "\n",
      "   contents_OrderedQueryPairs_15  \n",
      "0                            0.0  \n",
      "1                            0.0  \n",
      "2                            0.0  \n",
      "3                            0.0  \n",
      "4                            0.0  \n",
      "5                            0.0  \n",
      "6                            0.0  \n",
      "7                            1.0  \n",
      "8                            0.0  \n",
      "9                            3.0  \n",
      "\n",
      "[10 rows x 76 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6974598 entries, 0 to 6974597\n",
      "Data columns (total 76 columns):\n",
      " #   Column                                Dtype  \n",
      "---  ------                                -----  \n",
      " 0   qid                                   int32  \n",
      " 1   pid                                   int32  \n",
      " 2   rel                                   int32  \n",
      " 3   contents_BM25_k1_0.90_b_0.40          float32\n",
      " 4   contents_BM25_k1_1.20_b_0.75          float32\n",
      " 5   contents_BM25_k1_2.00_b_0.75          float32\n",
      " 6   contents_LMD_mu_1000                  float32\n",
      " 7   contents_LMD_mu_1500                  float32\n",
      " 8   contents_LMD_mu_2500                  float32\n",
      " 9   contents_LMJM_lambda_0.10             float32\n",
      " 10  contents_LMJM_lambda_0.40             float32\n",
      " 11  contents_LMJM_lambda_0.70             float32\n",
      " 12  contents_NTFIDF                       float32\n",
      " 13  contents_Prob                         float32\n",
      " 14  contents_DFR_GL2                      float32\n",
      " 15  contents_DFR_In_expB2                 float32\n",
      " 16  contents_DPH                          float32\n",
      " 17  contents_Proximity                    float32\n",
      " 18  contents_TPscore                      float32\n",
      " 19  contents_tpDistWindow100              float32\n",
      " 20  contents_DocSize                      float32\n",
      " 21  Entropy                               float32\n",
      " 22  StopCover                             float32\n",
      " 23  StopRatio                             float32\n",
      " 24  QueryLength                           float32\n",
      " 25  QueryLengthNonStopWords               float32\n",
      " 26  contents_QueryCoverageRatio           float32\n",
      " 27  UniqueQueryTerms                      float32\n",
      " 28  contents_MatchingTermCount            float32\n",
      " 29  contents_SCS                          float32\n",
      " 30  contents_TF_avg                       float32\n",
      " 31  contents_TF_sum                       float32\n",
      " 32  contents_TF_min                       float32\n",
      " 33  contents_TF_max                       float32\n",
      " 34  contents_TF_var                       float32\n",
      " 35  contents_TFIDF_avg                    float32\n",
      " 36  contents_TFIDF_sum                    float32\n",
      " 37  contents_TFIDF_min                    float32\n",
      " 38  contents_TFIDF_max                    float32\n",
      " 39  contents_TFIDF_var                    float32\n",
      " 40  contents_SCQ_avg                      float32\n",
      " 41  contents_SCQ_sum                      float32\n",
      " 42  contents_SCQ_min                      float32\n",
      " 43  contents_SCQ_max                      float32\n",
      " 44  contents_SCQ_var                      float32\n",
      " 45  contents_NormalizedTF_avg             float32\n",
      " 46  contents_NormalizedTF_sum             float32\n",
      " 47  contents_NormalizedTF_min             float32\n",
      " 48  contents_NormalizedTF_max             float32\n",
      " 49  contents_NormalizedTF_var             float32\n",
      " 50  contents_IDF_avg                      float32\n",
      " 51  contents_IDF_sum                      float32\n",
      " 52  contents_IDF_min                      float32\n",
      " 53  contents_IDF_max                      float32\n",
      " 54  contents_IDF_var                      float32\n",
      " 55  contents_IDF_maxminratio              float32\n",
      " 56  contents_IDF_confidence               float32\n",
      " 57  contents_ICTF_avg                     float32\n",
      " 58  contents_ICTF_sum                     float32\n",
      " 59  contents_ICTF_min                     float32\n",
      " 60  contents_ICTF_max                     float32\n",
      " 61  contents_ICTF_var                     float32\n",
      " 62  contents_ICTF_maxminratio             float32\n",
      " 63  contents_ICTF_confidence              float32\n",
      " 64  contents_UnorderedSequentialPairs_3   float32\n",
      " 65  contents_UnorderedSequentialPairs_8   float32\n",
      " 66  contents_UnorderedSequentialPairs_15  float32\n",
      " 67  contents_OrderedSequentialPairs_3     float32\n",
      " 68  contents_OrderedSequentialPairs_8     float32\n",
      " 69  contents_OrderedSequentialPairs_15    float32\n",
      " 70  contents_UnorderedQueryPairs_3        float32\n",
      " 71  contents_UnorderedQueryPairs_8        float32\n",
      " 72  contents_UnorderedQueryPairs_15       float32\n",
      " 73  contents_OrderedQueryPairs_3          float32\n",
      " 74  contents_OrderedQueryPairs_8          float32\n",
      " 75  contents_OrderedQueryPairs_15         float32\n",
      "dtypes: float32(73), int32(3)\n",
      "memory usage: 2.3 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_extracted = data_loader('train', sampled_train, queries, fe)\n",
    "# export(sampled_train, 'sampled_train_export.json')\n",
    "dev_extracted = data_loader('dev', dev, queries, fe)\n",
    "# export(dev, 'sampled_dev_export.json')\n",
    "del sampled_train, dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:27:57.655411Z",
     "start_time": "2020-12-05T06:27:57.649798Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def eval_mrr(dev_data):\n",
    "    score_tie_counter = 0\n",
    "    score_tie_query = set()\n",
    "\n",
    "    MRR = []\n",
    "    for qid, group in tqdm(dev_data.groupby('qid')):\n",
    "        group = group.reset_index()\n",
    "        rank = 0\n",
    "        prev_score = None\n",
    "        assert len(group['pid'].tolist()) == len(set(group['pid'].tolist()))\n",
    "        # stable sort is also used in LightGBM\n",
    "\n",
    "        for t in group.sort_values('score', ascending=False, kind='mergesort').itertuples():\n",
    "            if prev_score is not None and abs(t.score - prev_score) < 1e-8:\n",
    "                score_tie_counter += 1\n",
    "                score_tie_query.add(qid)\n",
    "            prev_score = t.score\n",
    "            prev_pid = t.pid\n",
    "            rank += 1\n",
    "            if t.rel>0:\n",
    "                MRR.append(1.0/rank)\n",
    "                break\n",
    "            elif rank == 10 or rank == len(group):\n",
    "                MRR.append(0.)\n",
    "                break\n",
    "\n",
    "    score_tie = f'score_tie occurs {score_tie_counter} times in {len(score_tie_query)} queries'\n",
    "    print(score_tie,np.mean(MRR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T07:20:21.007515Z",
     "start_time": "2020-12-05T07:20:20.987726Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_recall(dev_data):\n",
    "    score_tie_counter = 0\n",
    "    score_tie_query = set()\n",
    "\n",
    "    recall10 = []\n",
    "    recall20 = []\n",
    "    recall30 = []\n",
    "    recall50 = []\n",
    "    recall100 = []\n",
    "    recall200 = []\n",
    "    upper_limit = []\n",
    "    for qid, group in tqdm(dev_data.groupby('qid')):\n",
    "        group = group.reset_index()\n",
    "        rank = 0\n",
    "        prev_score = None\n",
    "        assert len(group['pid'].tolist()) == len(set(group['pid'].tolist()))\n",
    "        # stable sort is also used in LightGBM\n",
    "\n",
    "        for t in group.sort_values('score', ascending=False, kind='mergesort').itertuples():\n",
    "            if prev_score is not None and abs(t.score - prev_score) < 1e-8:\n",
    "                score_tie_counter += 1\n",
    "                score_tie_query.add(qid)\n",
    "            prev_score = t.score\n",
    "            prev_pid = t.pid\n",
    "            rank += 1\n",
    "            if t.rel>0:\n",
    "                if rank <= 10:\n",
    "                    recall10.append(1.0)\n",
    "                elif rank <= 20:\n",
    "                    recall20.append(1.0)\n",
    "                elif rank <= 30:\n",
    "                    recall30.append(1.0)\n",
    "                elif rank <= 50:\n",
    "                    recall50.append(1.0)\n",
    "                elif rank <= 100:\n",
    "                    recall100.append(1.0)\n",
    "                elif rank <= 200:\n",
    "                    recall200.append(1.0)\n",
    "                else:\n",
    "                    upper_limit.append(1.0)\n",
    "                break\n",
    "\n",
    "    score_tie = f'score_tie occurs {score_tie_counter} times in {len(score_tie_query)} queries'\n",
    "    print(score_tie,\n",
    "          np.mean(recall10),\n",
    "          np.mean(recall20),\n",
    "          np.mean(recall30),\n",
    "          np.mean(recall50),\n",
    "          np.mean(recall100),\n",
    "          np.mean(recall200),\n",
    "          np.mean(upper_limit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:27:59.689072Z",
     "start_time": "2020-12-05T06:27:57.686284Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_name = fe.feature_names()\n",
    "train_X = train_extracted['data'].loc[:, feature_name]\n",
    "train_Y = train_extracted['data']['rel']\n",
    "dev_X = dev_extracted['data'].loc[:, feature_name]\n",
    "dev_Y = dev_extracted['data']['rel']\n",
    "lgb_train = lgb.Dataset(train_X,label=train_Y,group=train_extracted['group'])\n",
    "lgb_valid = lgb.Dataset(dev_X,label=dev_Y,group=dev_extracted['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:27:59.733209Z",
     "start_time": "2020-12-05T06:27:59.692845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contents_BM25_k1_0.90_b_0.40',\n",
       " 'contents_BM25_k1_1.20_b_0.75',\n",
       " 'contents_BM25_k1_2.00_b_0.75',\n",
       " 'contents_LMD_mu_1000',\n",
       " 'contents_LMD_mu_1500',\n",
       " 'contents_LMD_mu_2500',\n",
       " 'contents_LMJM_lambda_0.10',\n",
       " 'contents_LMJM_lambda_0.40',\n",
       " 'contents_LMJM_lambda_0.70',\n",
       " 'contents_NTFIDF',\n",
       " 'contents_Prob',\n",
       " 'contents_DFR_GL2',\n",
       " 'contents_DFR_In_expB2',\n",
       " 'contents_DPH',\n",
       " 'contents_Proximity',\n",
       " 'contents_TPscore',\n",
       " 'contents_tpDistWindow100',\n",
       " 'contents_DocSize',\n",
       " 'Entropy',\n",
       " 'StopCover',\n",
       " 'StopRatio',\n",
       " 'QueryLength',\n",
       " 'QueryLengthNonStopWords',\n",
       " 'contents_QueryCoverageRatio',\n",
       " 'UniqueQueryTerms',\n",
       " 'contents_MatchingTermCount',\n",
       " 'contents_SCS',\n",
       " 'contents_TF_avg',\n",
       " 'contents_TF_sum',\n",
       " 'contents_TF_min',\n",
       " 'contents_TF_max',\n",
       " 'contents_TF_var',\n",
       " 'contents_TFIDF_avg',\n",
       " 'contents_TFIDF_sum',\n",
       " 'contents_TFIDF_min',\n",
       " 'contents_TFIDF_max',\n",
       " 'contents_TFIDF_var',\n",
       " 'contents_SCQ_avg',\n",
       " 'contents_SCQ_sum',\n",
       " 'contents_SCQ_min',\n",
       " 'contents_SCQ_max',\n",
       " 'contents_SCQ_var',\n",
       " 'contents_NormalizedTF_avg',\n",
       " 'contents_NormalizedTF_sum',\n",
       " 'contents_NormalizedTF_min',\n",
       " 'contents_NormalizedTF_max',\n",
       " 'contents_NormalizedTF_var',\n",
       " 'contents_IDF_avg',\n",
       " 'contents_IDF_sum',\n",
       " 'contents_IDF_min',\n",
       " 'contents_IDF_max',\n",
       " 'contents_IDF_var',\n",
       " 'contents_IDF_maxminratio',\n",
       " 'contents_IDF_confidence',\n",
       " 'contents_ICTF_avg',\n",
       " 'contents_ICTF_sum',\n",
       " 'contents_ICTF_min',\n",
       " 'contents_ICTF_max',\n",
       " 'contents_ICTF_var',\n",
       " 'contents_ICTF_maxminratio',\n",
       " 'contents_ICTF_confidence',\n",
       " 'contents_UnorderedSequentialPairs_3',\n",
       " 'contents_UnorderedSequentialPairs_8',\n",
       " 'contents_UnorderedSequentialPairs_15',\n",
       " 'contents_OrderedSequentialPairs_3',\n",
       " 'contents_OrderedSequentialPairs_8',\n",
       " 'contents_OrderedSequentialPairs_15',\n",
       " 'contents_UnorderedQueryPairs_3',\n",
       " 'contents_UnorderedQueryPairs_8',\n",
       " 'contents_UnorderedQueryPairs_15',\n",
       " 'contents_OrderedQueryPairs_3',\n",
       " 'contents_OrderedQueryPairs_8',\n",
       " 'contents_OrderedQueryPairs_15']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:59:36.218257Z",
     "start_time": "2020-12-05T06:42:31.476253Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total groups: 431848, total data: 4770762\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.204520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12028\n",
      "[LightGBM] [Info] Number of data points in the train set: 4770762, number of used features: 65\n",
      "[LightGBM] [Info] Total groups: 6980, total data: 6974598\n",
      "0.34519569328845834\n",
      "739\n",
      "[('contents_DFR_In_expB2', 2233), ('contents_Prob', 1570), ('contents_SCQ_var', 1570), ('contents_SCQ_avg', 1473), ('contents_NormalizedTF_var', 1328), ('contents_TPscore', 1258), ('contents_NTFIDF', 1236), ('contents_DFR_GL2', 1235), ('contents_TFIDF_var', 1217), ('contents_TFIDF_max', 1216), ('contents_Proximity', 1178), ('contents_NormalizedTF_avg', 1177), ('contents_SCQ_max', 1164), ('contents_NormalizedTF_min', 1086), ('contents_IDF_maxminratio', 1002), ('contents_ICTF_maxminratio', 1001), ('contents_DocSize', 941), ('contents_NormalizedTF_sum', 940), ('contents_TFIDF_sum', 932), ('contents_BM25_k1_0.90_b_0.40', 924), ('contents_BM25_k1_2.00_b_0.75', 924), ('contents_TF_var', 902), ('contents_TFIDF_avg', 902), ('contents_LMJM_lambda_0.70', 727), ('contents_IDF_sum', 717), ('contents_BM25_k1_1.20_b_0.75', 706), ('contents_UnorderedQueryPairs_15', 689), ('contents_SCS', 685), ('contents_LMJM_lambda_0.10', 650), ('contents_ICTF_max', 625), ('contents_SCQ_sum', 605), ('contents_LMD_mu_1000', 590), ('contents_IDF_avg', 589), ('contents_UnorderedSequentialPairs_15', 584), ('contents_TF_avg', 576), ('contents_IDF_max', 576), ('contents_IDF_confidence', 559), ('contents_ICTF_var', 549), ('contents_ICTF_avg', 547), ('contents_ICTF_confidence', 547), ('contents_QueryCoverageRatio', 544), ('contents_IDF_var', 511), ('contents_LMJM_lambda_0.40', 507), ('contents_UnorderedQueryPairs_3', 461), ('contents_OrderedQueryPairs_3', 460), ('contents_UnorderedQueryPairs_8', 459), ('contents_OrderedQueryPairs_8', 456), ('contents_OrderedQueryPairs_15', 429), ('contents_OrderedSequentialPairs_3', 425), ('QueryLength', 373), ('contents_MatchingTermCount', 368), ('contents_TF_sum', 368), ('contents_ICTF_sum', 349), ('contents_LMD_mu_2500', 346), ('contents_LMD_mu_1500', 325), ('contents_UnorderedSequentialPairs_8', 310), ('contents_UnorderedSequentialPairs_3', 306), ('contents_OrderedSequentialPairs_15', 256), ('contents_OrderedSequentialPairs_8', 238), ('contents_TF_max', 237), ('contents_tpDistWindow100', 92), ('StopRatio', 32), ('UniqueQueryTerms', 21), ('QueryLengthNonStopWords', 15), ('contents_DPH', 0), ('Entropy', 0), ('StopCover', 0), ('contents_TF_min', 0), ('contents_TFIDF_min', 0), ('contents_SCQ_min', 0), ('contents_NormalizedTF_max', 0), ('contents_IDF_min', 0), ('contents_ICTF_min', 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6980/6980 [00:42<00:00, 163.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_tie occurs 889 times in 666 queries 0.21174358711966162\n",
      "[LightGBM] [Info] Total groups: 431848, total data: 4770762\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.214093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12028\n",
      "[LightGBM] [Info] Number of data points in the train set: 4770762, number of used features: 65\n",
      "[LightGBM] [Info] Total groups: 6980, total data: 6974598\n",
      "0.34236094055578287\n",
      "255\n",
      "[('contents_DFR_In_expB2', 1026), ('contents_Prob', 717), ('contents_DFR_GL2', 549), ('contents_SCQ_avg', 534), ('contents_NormalizedTF_var', 513), ('contents_TPscore', 467), ('contents_TFIDF_var', 458), ('contents_LMJM_lambda_0.70', 447), ('contents_NormalizedTF_min', 423), ('contents_TFIDF_max', 416), ('contents_SCQ_var', 391), ('contents_QueryCoverageRatio', 381), ('contents_BM25_k1_0.90_b_0.40', 379), ('contents_MatchingTermCount', 379), ('contents_UnorderedQueryPairs_15', 361), ('contents_LMD_mu_1000', 360), ('contents_TF_var', 323), ('contents_NormalizedTF_sum', 317), ('contents_SCQ_max', 310), ('contents_BM25_k1_2.00_b_0.75', 304), ('contents_NormalizedTF_avg', 295), ('contents_OrderedSequentialPairs_3', 291), ('contents_DocSize', 281), ('contents_LMJM_lambda_0.10', 273), ('contents_NTFIDF', 264), ('contents_TFIDF_sum', 253), ('contents_OrderedQueryPairs_3', 251), ('contents_LMJM_lambda_0.40', 221), ('contents_BM25_k1_1.20_b_0.75', 218), ('contents_TF_sum', 216), ('contents_UnorderedSequentialPairs_15', 215), ('contents_UnorderedQueryPairs_8', 212), ('contents_Proximity', 211), ('contents_OrderedQueryPairs_8', 204), ('contents_UnorderedQueryPairs_3', 201), ('contents_IDF_sum', 189), ('contents_TF_avg', 188), ('contents_SCQ_sum', 183), ('contents_TFIDF_avg', 174), ('contents_IDF_maxminratio', 159), ('contents_ICTF_maxminratio', 158), ('contents_UnorderedSequentialPairs_3', 158), ('contents_IDF_avg', 153), ('contents_LMD_mu_1500', 146), ('contents_OrderedQueryPairs_15', 145), ('contents_IDF_max', 137), ('contents_ICTF_max', 115), ('contents_SCS', 114), ('contents_ICTF_confidence', 113), ('contents_IDF_var', 105), ('contents_IDF_confidence', 105), ('contents_UnorderedSequentialPairs_8', 101), ('contents_LMD_mu_2500', 97), ('contents_ICTF_avg', 93), ('contents_OrderedSequentialPairs_8', 91), ('contents_ICTF_var', 82), ('contents_TF_max', 81), ('contents_OrderedSequentialPairs_15', 74), ('QueryLength', 64), ('contents_ICTF_sum', 61), ('contents_tpDistWindow100', 26), ('StopRatio', 23), ('UniqueQueryTerms', 9), ('QueryLengthNonStopWords', 4), ('contents_DPH', 1), ('Entropy', 0), ('StopCover', 0), ('contents_TF_min', 0), ('contents_TFIDF_min', 0), ('contents_SCQ_min', 0), ('contents_NormalizedTF_max', 0), ('contents_IDF_min', 0), ('contents_ICTF_min', 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6980/6980 [00:36<00:00, 191.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_tie occurs 836 times in 627 queries 0.21011449947696365\n",
      "[LightGBM] [Info] Total groups: 431848, total data: 4770762\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.209508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12028\n",
      "[LightGBM] [Info] Number of data points in the train set: 4770762, number of used features: 65\n",
      "[LightGBM] [Info] Total groups: 6980, total data: 6974598\n",
      "0.34248846856475795\n",
      "219\n",
      "[('contents_DFR_In_expB2', 882), ('contents_Prob', 640), ('contents_DFR_GL2', 499), ('contents_SCQ_avg', 491), ('contents_LMJM_lambda_0.70', 457), ('contents_NormalizedTF_var', 444), ('contents_TPscore', 409), ('contents_QueryCoverageRatio', 383), ('contents_SCQ_var', 369), ('contents_NormalizedTF_min', 367), ('contents_TFIDF_var', 366), ('contents_TFIDF_max', 361), ('contents_MatchingTermCount', 325), ('contents_BM25_k1_0.90_b_0.40', 319), ('contents_LMD_mu_1000', 318), ('contents_NormalizedTF_sum', 307), ('contents_UnorderedQueryPairs_15', 299), ('contents_LMJM_lambda_0.10', 287), ('contents_OrderedSequentialPairs_3', 273), ('contents_TF_var', 268), ('contents_NormalizedTF_avg', 248), ('contents_SCQ_max', 233), ('contents_OrderedQueryPairs_3', 232), ('contents_LMJM_lambda_0.40', 223), ('contents_DocSize', 218), ('contents_BM25_k1_2.00_b_0.75', 216), ('contents_NTFIDF', 215), ('contents_UnorderedQueryPairs_3', 207), ('contents_UnorderedSequentialPairs_15', 204), ('contents_TFIDF_sum', 192), ('contents_TF_sum', 185), ('contents_UnorderedQueryPairs_8', 183), ('contents_OrderedQueryPairs_8', 180), ('contents_BM25_k1_1.20_b_0.75', 179), ('contents_TF_avg', 174), ('contents_Proximity', 166), ('contents_IDF_avg', 150), ('contents_IDF_sum', 147), ('contents_SCQ_sum', 145), ('contents_UnorderedSequentialPairs_3', 130), ('contents_TFIDF_avg', 121), ('contents_OrderedQueryPairs_15', 121), ('contents_LMD_mu_1500', 117), ('contents_IDF_maxminratio', 100), ('contents_IDF_max', 99), ('contents_OrderedSequentialPairs_8', 93), ('contents_LMD_mu_2500', 91), ('contents_ICTF_max', 91), ('contents_UnorderedSequentialPairs_8', 81), ('contents_SCS', 78), ('contents_IDF_confidence', 75), ('contents_ICTF_maxminratio', 75), ('contents_ICTF_sum', 69), ('contents_TF_max', 68), ('contents_ICTF_avg', 67), ('contents_IDF_var', 66), ('contents_ICTF_confidence', 64), ('QueryLength', 60), ('contents_ICTF_var', 60), ('contents_OrderedSequentialPairs_15', 46), ('StopRatio', 19), ('contents_tpDistWindow100', 17), ('QueryLengthNonStopWords', 5), ('UniqueQueryTerms', 4), ('contents_DPH', 0), ('Entropy', 0), ('StopCover', 0), ('contents_TF_min', 0), ('contents_TFIDF_min', 0), ('contents_SCQ_min', 0), ('contents_NormalizedTF_max', 0), ('contents_IDF_min', 0), ('contents_ICTF_min', 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6980/6980 [00:38<00:00, 183.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_tie occurs 834 times in 621 queries 0.2099906194569518\n",
      "[LightGBM] [Info] Total groups: 431848, total data: 4770762\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.189235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12028\n",
      "[LightGBM] [Info] Number of data points in the train set: 4770762, number of used features: 65\n",
      "[LightGBM] [Info] Total groups: 6980, total data: 6974598\n",
      "0.34337646488076284\n",
      "942\n",
      "[('contents_DFR_In_expB2', 2631), ('contents_SCQ_var', 1980), ('contents_Prob', 1859), ('contents_SCQ_avg', 1813), ('contents_NTFIDF', 1697), ('contents_SCQ_max', 1680), ('contents_TFIDF_max', 1621), ('contents_DFR_GL2', 1617), ('contents_NormalizedTF_var', 1613), ('contents_TPscore', 1560), ('contents_Proximity', 1558), ('contents_TFIDF_var', 1525), ('contents_NormalizedTF_avg', 1483), ('contents_IDF_maxminratio', 1429), ('contents_ICTF_maxminratio', 1369), ('contents_NormalizedTF_min', 1364), ('contents_DocSize', 1300), ('contents_TFIDF_sum', 1256), ('contents_TFIDF_avg', 1192), ('contents_BM25_k1_0.90_b_0.40', 1190), ('contents_BM25_k1_2.00_b_0.75', 1166), ('contents_TF_var', 1149), ('contents_NormalizedTF_sum', 1078), ('contents_BM25_k1_1.20_b_0.75', 893), ('contents_ICTF_avg', 873), ('contents_IDF_avg', 858), ('contents_ICTF_max', 855), ('contents_SCS', 853), ('contents_LMJM_lambda_0.70', 850), ('contents_IDF_sum', 850), ('contents_UnorderedQueryPairs_15', 802), ('contents_LMJM_lambda_0.10', 798), ('contents_SCQ_sum', 780), ('contents_ICTF_var', 764), ('contents_IDF_max', 761), ('contents_IDF_confidence', 761), ('contents_IDF_var', 760), ('contents_ICTF_confidence', 747), ('contents_LMD_mu_1000', 678), ('contents_TF_avg', 675), ('contents_UnorderedSequentialPairs_15', 669), ('contents_LMJM_lambda_0.40', 587), ('contents_UnorderedQueryPairs_3', 584), ('contents_UnorderedQueryPairs_8', 575), ('contents_QueryCoverageRatio', 564), ('contents_OrderedQueryPairs_15', 552), ('contents_ICTF_sum', 537), ('contents_OrderedQueryPairs_3', 513), ('contents_OrderedSequentialPairs_3', 512), ('QueryLength', 508), ('contents_OrderedQueryPairs_8', 504), ('contents_LMD_mu_2500', 475), ('contents_TF_sum', 469), ('contents_MatchingTermCount', 413), ('contents_LMD_mu_1500', 410), ('contents_UnorderedSequentialPairs_8', 392), ('contents_UnorderedSequentialPairs_3', 345), ('contents_OrderedSequentialPairs_15', 325), ('contents_OrderedSequentialPairs_8', 316), ('contents_TF_max', 254), ('contents_tpDistWindow100', 127), ('UniqueQueryTerms', 38), ('StopRatio', 28), ('QueryLengthNonStopWords', 18), ('contents_DPH', 1), ('Entropy', 0), ('StopCover', 0), ('contents_TF_min', 0), ('contents_TFIDF_min', 0), ('contents_SCQ_min', 0), ('contents_NormalizedTF_max', 0), ('contents_IDF_min', 0), ('contents_ICTF_min', 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6980/6980 [00:39<00:00, 175.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_tie occurs 827 times in 621 queries 0.20922982898985762\n",
      "[LightGBM] [Info] Total groups: 431848, total data: 4770762\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.220211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12028\n",
      "[LightGBM] [Info] Number of data points in the train set: 4770762, number of used features: 65\n",
      "[LightGBM] [Info] Total groups: 6980, total data: 6974598\n",
      "0.34078870468913447\n",
      "222\n",
      "[('contents_DFR_In_expB2', 905), ('contents_Prob', 686), ('contents_SCQ_avg', 501), ('contents_DFR_GL2', 469), ('contents_NormalizedTF_var', 418), ('contents_TPscore', 414), ('contents_LMJM_lambda_0.70', 407), ('contents_TFIDF_var', 398), ('contents_QueryCoverageRatio', 385), ('contents_TFIDF_max', 382), ('contents_LMD_mu_1000', 376), ('contents_SCQ_var', 366), ('contents_BM25_k1_0.90_b_0.40', 349), ('contents_NormalizedTF_min', 344), ('contents_MatchingTermCount', 327), ('contents_UnorderedQueryPairs_15', 294), ('contents_NormalizedTF_sum', 279), ('contents_LMJM_lambda_0.10', 272), ('contents_TF_var', 267), ('contents_OrderedSequentialPairs_3', 243), ('contents_SCQ_max', 238), ('contents_BM25_k1_2.00_b_0.75', 236), ('contents_OrderedQueryPairs_3', 232), ('contents_NTFIDF', 227), ('contents_NormalizedTF_avg', 227), ('contents_DocSize', 220), ('contents_UnorderedSequentialPairs_15', 207), ('contents_UnorderedQueryPairs_3', 206), ('contents_TF_sum', 205), ('contents_OrderedQueryPairs_8', 197), ('contents_UnorderedQueryPairs_8', 191), ('contents_TFIDF_sum', 187), ('contents_TF_avg', 185), ('contents_LMJM_lambda_0.40', 182), ('contents_BM25_k1_1.20_b_0.75', 176), ('contents_Proximity', 169), ('contents_SCQ_sum', 165), ('contents_IDF_sum', 165), ('contents_IDF_avg', 156), ('contents_OrderedQueryPairs_15', 132), ('contents_TFIDF_avg', 126), ('contents_UnorderedSequentialPairs_3', 126), ('contents_IDF_maxminratio', 124), ('contents_ICTF_maxminratio', 111), ('contents_LMD_mu_2500', 110), ('contents_LMD_mu_1500', 106), ('contents_IDF_max', 104), ('contents_ICTF_max', 93), ('contents_OrderedSequentialPairs_8', 86), ('contents_TF_max', 79), ('contents_UnorderedSequentialPairs_8', 79), ('contents_ICTF_confidence', 78), ('contents_IDF_var', 77), ('contents_SCS', 70), ('contents_ICTF_avg', 69), ('contents_IDF_confidence', 66), ('contents_ICTF_var', 61), ('QueryLength', 59), ('contents_ICTF_sum', 54), ('contents_OrderedSequentialPairs_15', 44), ('contents_tpDistWindow100', 20), ('StopRatio', 20), ('UniqueQueryTerms', 10), ('QueryLengthNonStopWords', 6), ('contents_DPH', 1), ('Entropy', 0), ('StopCover', 0), ('contents_TF_min', 0), ('contents_TFIDF_min', 0), ('contents_SCQ_min', 0), ('contents_NormalizedTF_max', 0), ('contents_IDF_min', 0), ('contents_ICTF_min', 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6980/6980 [00:39<00:00, 177.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_tie occurs 837 times in 626 queries 0.20870855505525993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'lambdarank',\n",
    "    'max_bin':255,\n",
    "    'num_leaves':63,\n",
    "    'max_depth':-1,\n",
    "    'min_data_in_leaf':50,\n",
    "    'min_sum_hessian_in_leaf':0,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq':50,\n",
    "    'feature_fraction':1,\n",
    "    'learning_rate':0.05,\n",
    "    'num_boost_round':2000,\n",
    "    'early_stopping_round':500,\n",
    "    'metric':['map'],\n",
    "    'eval_at':[10],\n",
    "    'label_gain':[0,1],\n",
    "    'lambdarank_truncation_level':20,\n",
    "    'num_threads':max(multiprocessing.cpu_count()//2,1)\n",
    "}\n",
    "num_boost_round = params.pop('num_boost_round')\n",
    "early_stopping_round = params.pop('early_stopping_round')\n",
    "eval_results={}\n",
    "dev_extracted['data']['score']=0.\n",
    "for seed in [12345,31345,21356,65743,68786]:\n",
    "    params['seed'] = seed\n",
    "    gbm = lgb.train(params, lgb_train, \n",
    "                    valid_sets=lgb_valid,\n",
    "                    num_boost_round=num_boost_round,\n",
    "                    early_stopping_rounds =early_stopping_round,\n",
    "                    feature_name=feature_name,\n",
    "                    evals_result=eval_results,\n",
    "                    verbose_eval=False)\n",
    "    dev_extracted['data']['score'] += gbm.predict(dev_X)\n",
    "    best_score = gbm.best_score['valid_0']['map@10']\n",
    "    print(best_score)\n",
    "    best_iteration = gbm.best_iteration\n",
    "    print(best_iteration)\n",
    "    eval_map = eval_results['valid_0']['map@10']\n",
    "    # print(eval_map)\n",
    "    feature_importances = sorted(list(zip(feature_name,gbm.feature_importance().tolist())),key=lambda x:x[1],reverse=True)\n",
    "    print(feature_importances)\n",
    "    eval_mrr(dev_extracted['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-05T07:22:49.781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.176342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12028\n",
      "[LightGBM] [Info] Number of data points in the train set: 3816608, number of used features: 65\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.178090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12028\n",
      "[LightGBM] [Info] Number of data points in the train set: 3816609, number of used features: 65\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12028\n",
      "[LightGBM] [Info] Number of data points in the train set: 3816607, number of used features: 65\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.159178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12028\n",
      "[LightGBM] [Info] Number of data points in the train set: 3816612, number of used features: 65\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.162083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12028\n",
      "[LightGBM] [Info] Number of data points in the train set: 3816612, number of used features: 65\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'lambdarank',\n",
    "    'max_bin':255,\n",
    "    'num_leaves':63,\n",
    "    'max_depth':-1,\n",
    "    'min_data_in_leaf':50,\n",
    "    'min_sum_hessian_in_leaf':100,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq':50,\n",
    "    'feature_fraction':1,\n",
    "    'learning_rate':0.1,\n",
    "    'num_boost_round':1000,\n",
    "    'metric':['recall'],\n",
    "    'eval_at':[10],\n",
    "    'label_gain':[0,1],\n",
    "    'lambdarank_truncation_level':20,\n",
    "    'seed':12345,\n",
    "    'num_threads':max(multiprocessing.cpu_count()//2,1)\n",
    "}\n",
    "\n",
    "num_boost_round = params.pop('num_boost_round')\n",
    "eval_results={}\n",
    "cv_gbm = lgb.cv(params, lgb_train, nfold=5, \n",
    "                num_boost_round=num_boost_round,\n",
    "                feature_name=feature_name,\n",
    "                verbose_eval=False,\n",
    "                return_cvbooster=True)\n",
    "dev_extracted['data']['score'] = 0.\n",
    "for gbm in cv_gbm['cvbooster'].boosters:\n",
    "    dev_extracted['data']['score']+=gbm.predict(dev_X)\n",
    "feature_importances = sorted(list(zip(feature_name,gbm.feature_importance().tolist())),key=lambda x:x[1],reverse=True)\n",
    "print(feature_importances)\n",
    "eval_mrr(dev_extracted['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T07:21:19.044716Z",
     "start_time": "2020-12-05T07:20:29.937097Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6980/6980 [00:48<00:00, 142.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_tie occurs 242967 times in 2952 queries 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_recall(dev_extracted['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
